<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Hierarchical models | Structural Bayesian Techniques for Experimental and Behavioral Economics</title>
  <meta name="description" content="6 Hierarchical models | Structural Bayesian Techniques for Experimental and Behavioral Economics" />
  <meta name="generator" content="bookdown 0.38 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Hierarchical models | Structural Bayesian Techniques for Experimental and Behavioral Economics" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Hierarchical models | Structural Bayesian Techniques for Experimental and Behavioral Economics" />
  
  
  

<meta name="author" content="James R. Bland" />


<meta name="date" content="2025-03-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="representative-agent-and-participant-specific-models.html"/>
<link rel="next" href="mixture-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="section.html#section" id="toc-section"></a></li>
<li class="chapter" data-level="" data-path="setting-the-stage.html"><a href="setting-the-stage.html"><i class="fa fa-check"></i>Setting the stage</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-does-your-theory-say-about-your-data"><i class="fa fa-check"></i><b>1.1</b> What does your theory say about your data?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-do-your-data-say-about-your-theory"><i class="fa fa-check"></i><b>1.2</b> What do your data say about your theory?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-do-your-parameters-say-about-other-things"><i class="fa fa-check"></i><b>1.3</b> What do your parameters say about other things?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#what-does-your-expertise-say-about-your-parameters"><i class="fa fa-check"></i><b>1.4</b> What does your expertise say about your parameters?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html"><i class="fa fa-check"></i><b>2</b> Getting started in <em>Stan</em></a>
<ul>
<li class="chapter" data-level="2.1" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#installation-in-r"><i class="fa fa-check"></i><b>2.1</b> Installation in <em>R</em></a></li>
<li class="chapter" data-level="2.2" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#the-anatomy-of-a-stan-program"><i class="fa fa-check"></i><b>2.2</b> The anatomy of a <em>Stan</em> program</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#data-block"><i class="fa fa-check"></i><b>2.2.1</b> Data block</a></li>
<li class="chapter" data-level="2.2.2" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#transformed-data-block"><i class="fa fa-check"></i><b>2.2.2</b> Transformed data block</a></li>
<li class="chapter" data-level="2.2.3" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#parameters-block"><i class="fa fa-check"></i><b>2.2.3</b> Parameters block</a></li>
<li class="chapter" data-level="2.2.4" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#model-block"><i class="fa fa-check"></i><b>2.2.4</b> Model block</a></li>
<li class="chapter" data-level="2.2.5" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#generated-quantities-block"><i class="fa fa-check"></i><b>2.2.5</b> Generated quantities block</a></li>
<li class="chapter" data-level="2.2.6" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#the-final-product"><i class="fa fa-check"></i><b>2.2.6</b> The final product</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#estimating-a-model"><i class="fa fa-check"></i><b>2.3</b> Estimating a model</a></li>
<li class="chapter" data-level="2.4" data-path="getting-started-in-stan.html"><a href="getting-started-in-stan.html#looking-at-the-results"><i class="fa fa-check"></i><b>2.4</b> Looking at the results</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html"><i class="fa fa-check"></i><b>3</b> Probabilistic models of behavior</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#the-problem-with-deterministic-models"><i class="fa fa-check"></i><b>3.1</b> The problem with deterministic models</a></li>
<li class="chapter" data-level="3.2" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#what-is-a-probabilistic-model"><i class="fa fa-check"></i><b>3.2</b> What <em>is</em> a probabilistic model?</a></li>
<li class="chapter" data-level="3.3" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#example-dataset-and-model"><i class="fa fa-check"></i><b>3.3</b> Example dataset and model</a></li>
<li class="chapter" data-level="3.4" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#optimal-choice-plus-an-error"><i class="fa fa-check"></i><b>3.4</b> Optimal choice plus an error</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#estimating-a-model-1"><i class="fa fa-check"></i><b>3.4.1</b> Estimating a model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#utility-based-models"><i class="fa fa-check"></i><b>3.5</b> Utility-based models</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#estimating-a-model-2"><i class="fa fa-check"></i><b>3.5.1</b> Estimating a model</a></li>
<li class="chapter" data-level="3.5.2" data-path="probabilistic-models-of-behavior.html"><a href="probabilistic-models-of-behavior.html#doing-something-with-the-estimates"><i class="fa fa-check"></i><b>3.5.2</b> Doing something with the estimates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html"><i class="fa fa-check"></i><b>4</b> Considerations for choosing a prior</a>
<ul>
<li class="chapter" data-level="4.1" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#example-model-and-experiment"><i class="fa fa-check"></i><b>4.1</b> Example model and experiment</a></li>
<li class="chapter" data-level="4.2" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#getting-the-support-right"><i class="fa fa-check"></i><b>4.2</b> Getting the support right</a></li>
<li class="chapter" data-level="4.3" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#eliciting-reasonable-priors"><i class="fa fa-check"></i><b>4.3</b> Eliciting reasonable priors</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#parameter-values-and-the-prior-pushforward-check"><i class="fa fa-check"></i><b>4.3.1</b> Parameter values and the prior pushforward check</a></li>
<li class="chapter" data-level="4.3.2" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#predictions-and-other-derived-quantities-the-prior-predictive-check"><i class="fa fa-check"></i><b>4.3.2</b> Predictions and other derived quantities: The prior predictive check</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#assessing-the-sampling-performance-of-a-prior"><i class="fa fa-check"></i><b>4.4</b> Assessing the sampling performance of a prior</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#does-our-model-recover-its-parameters-well"><i class="fa fa-check"></i><b>4.4.1</b> Does our model recover its parameters well?</a></li>
<li class="chapter" data-level="4.4.2" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#do-we-see-any-pathologies-in-the-estimation-process"><i class="fa fa-check"></i><b>4.4.2</b> Do we see any pathologies in the estimation process?</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="considerations-for-choosing-a-prior.html"><a href="considerations-for-choosing-a-prior.html#r-code-used-for-this-chapter"><i class="fa fa-check"></i><b>4.5</b> <em>R</em> code used for this chapter</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="building-blocks.html"><a href="building-blocks.html"><i class="fa fa-check"></i>Building blocks</a></li>
<li class="chapter" data-level="5" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html"><i class="fa fa-check"></i><b>5</b> Representative agent and participant-specific models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#participant-specific-models"><i class="fa fa-check"></i><b>5.1</b> Participant-specific models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#example-data-and-economic-model"><i class="fa fa-check"></i><b>5.1.1</b> Example data and economic model</a></li>
<li class="chapter" data-level="5.1.2" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#going-to-the-probabilistic-model"><i class="fa fa-check"></i><b>5.1.2</b> Going to the probabilistic model</a></li>
<li class="chapter" data-level="5.1.3" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#a-short-side-quest-into-canned-estimation-techniques"><i class="fa fa-check"></i><b>5.1.3</b> A short side quest into canned estimation techniques</a></li>
<li class="chapter" data-level="5.1.4" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#assigning-priors"><i class="fa fa-check"></i><b>5.1.4</b> Assigning priors</a></li>
<li class="chapter" data-level="5.1.5" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#estimating-the-model-for-one-participant"><i class="fa fa-check"></i><b>5.1.5</b> Estimating the model for one participant</a></li>
<li class="chapter" data-level="5.1.6" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#estimating-the-model-for-all-participants"><i class="fa fa-check"></i><b>5.1.6</b> Estimating the model for all participants</a></li>
<li class="chapter" data-level="5.1.7" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#but-we-could-be-learning-more"><i class="fa fa-check"></i><b>5.1.7</b> But we could be learning more!</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="representative-agent-and-participant-specific-models.html"><a href="representative-agent-and-participant-specific-models.html#actual-representative-agent-models-pooled-models"><i class="fa fa-check"></i><b>5.2</b> Actual representative agent models (pooled models)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hierarchical-models.html"><a href="hierarchical-models.html"><i class="fa fa-check"></i><b>6</b> Hierarchical models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-random-sample-of-participants-walks-into-your-lab"><i class="fa fa-check"></i><b>6.1</b> A random sample of participants walks into your lab</a></li>
<li class="chapter" data-level="6.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#the-anatomy-of-a-basic-hierarchical-model"><i class="fa fa-check"></i><b>6.2</b> The anatomy of a basic hierarchical model</a></li>
<li class="chapter" data-level="6.3" data-path="hierarchical-models.html"><a href="hierarchical-models.html#accounting-for-unobserved-heterogeneity"><i class="fa fa-check"></i><b>6.3</b> Accounting for unobserved heterogeneity</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#the-last-time-you-will-integrate-the-likelihood-probably"><i class="fa fa-check"></i><b>6.3.1</b> The last time you will integrate the likelihood, probably</a></li>
<li class="chapter" data-level="6.3.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#data-augmentation"><i class="fa fa-check"></i><b>6.3.2</b> Data augmentation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hierarchical-models.html"><a href="hierarchical-models.html#a-multivariate-normal-hierarchical-model"><i class="fa fa-check"></i><b>6.4</b> A multivariate normal hierarchical model</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#decomposing-the-variance-covariance-matrix"><i class="fa fa-check"></i><b>6.4.1</b> Decomposing the variance-covariance matrix</a></li>
<li class="chapter" data-level="6.4.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#transformed-parameters-and-normal-distributions"><i class="fa fa-check"></i><b>6.4.2</b> Transformed parameters and normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hierarchical-models.html"><a href="hierarchical-models.html#example-again-with-bfs2019"><i class="fa fa-check"></i><b>6.5</b> Example: again with <span class="citation">Bruhin, Fehr, and Schunk (2019)</span></a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="hierarchical-models.html"><a href="hierarchical-models.html#no-correlation-between-individual-level-parameters"><i class="fa fa-check"></i><b>6.5.1</b> No correlation between individual-level parameters</a></li>
<li class="chapter" data-level="6.5.2" data-path="hierarchical-models.html"><a href="hierarchical-models.html#correlation-between-individual-level-parameters"><i class="fa fa-check"></i><b>6.5.2</b> Correlation between individual-level parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mixture-models.html"><a href="mixture-models.html"><i class="fa fa-check"></i><b>7</b> Mixture models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mixture-models.html"><a href="mixture-models.html#a-menu-of-models"><i class="fa fa-check"></i><b>7.1</b> A menu of models</a></li>
<li class="chapter" data-level="7.2" data-path="mixture-models.html"><a href="mixture-models.html#dichotomous-and-toolbox-mixture-models"><i class="fa fa-check"></i><b>7.2</b> Dichotomous and toolbox mixture models</a></li>
<li class="chapter" data-level="7.3" data-path="mixture-models.html"><a href="mixture-models.html#coding-peculearities"><i class="fa fa-check"></i><b>7.3</b> Coding peculearities</a></li>
<li class="chapter" data-level="7.4" data-path="mixture-models.html"><a href="mixture-models.html#example-experiment-av2001"><i class="fa fa-check"></i><b>7.4</b> Example experiment: <span class="citation">Andreoni and Vesterlund (2001)</span></a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mixture-models.html"><a href="mixture-models.html#as-basic-as-it-gets"><i class="fa fa-check"></i><b>7.4.1</b> As basic as it gets</a></li>
<li class="chapter" data-level="7.4.2" data-path="mixture-models.html"><a href="mixture-models.html#adding-some-heterogeneity"><i class="fa fa-check"></i><b>7.4.2</b> Adding some heterogeneity</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="mixture-models.html"><a href="mixture-models.html#some-code-used-to-estimate-the-models"><i class="fa fa-check"></i><b>7.5</b> Some code used to estimate the models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html"><i class="fa fa-check"></i><b>8</b> Speeding up your <em>Stan</em> code</a>
<ul>
<li class="chapter" data-level="8.1" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#example-dataset-and-model-1"><i class="fa fa-check"></i><b>8.1</b> Example dataset and model</a></li>
<li class="chapter" data-level="8.2" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#a-really-slow-way-to-estimate-the-model"><i class="fa fa-check"></i><b>8.2</b> A really slow way to estimate the model</a></li>
<li class="chapter" data-level="8.3" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#pre-computing-things"><i class="fa fa-check"></i><b>8.3</b> Pre-computing things</a></li>
<li class="chapter" data-level="8.4" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#vectorization"><i class="fa fa-check"></i><b>8.4</b> Vectorization</a></li>
<li class="chapter" data-level="8.5" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#within-chain-parallelization-with-reduce_sum"><i class="fa fa-check"></i><b>8.5</b> Within-chain parallelization with <code>reduce_sum()</code></a></li>
<li class="chapter" data-level="8.6" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#evaluating-the-implementations"><i class="fa fa-check"></i><b>8.6</b> Evaluating the implementations</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#pre-computing-and-vectorization"><i class="fa fa-check"></i><b>8.6.1</b> Pre-computing and vectorization</a></li>
<li class="chapter" data-level="8.6.2" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#within-chain-parallelization"><i class="fa fa-check"></i><b>8.6.2</b> Within-chain parallelization</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#r-code-to-estimate-models"><i class="fa fa-check"></i><b>8.7</b> <em>R</em> code to estimate models</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#slow-pre-computed-and-vectorized-models"><i class="fa fa-check"></i><b>8.7.1</b> Slow, pre-computed, and vectorized models</a></li>
<li class="chapter" data-level="8.7.2" data-path="speeding-up-your-stan-code.html"><a href="speeding-up-your-stan-code.html#parallelized-model"><i class="fa fa-check"></i><b>8.7.2</b> Parallelized model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i>Applications</a></li>
<li class="chapter" data-level="9" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html"><i class="fa fa-check"></i><b>9</b> Application: Experience-Weighted Attraction</a>
<ul>
<li class="chapter" data-level="9.1" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#the-model-at-the-individual-level"><i class="fa fa-check"></i><b>9.1</b> The model at the individual level</a></li>
<li class="chapter" data-level="9.2" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#some-computational-and-coding-issues"><i class="fa fa-check"></i><b>9.2</b> Some computational and coding issues</a></li>
<li class="chapter" data-level="9.3" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#representative-agent-models"><i class="fa fa-check"></i><b>9.3</b> Representative agent models</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#prior-calibration"><i class="fa fa-check"></i><b>9.3.1</b> Prior calibration</a></li>
<li class="chapter" data-level="9.3.2" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#the-stan-model"><i class="fa fa-check"></i><b>9.3.2</b> The <em>Stan</em> model</a></li>
<li class="chapter" data-level="9.3.3" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#results"><i class="fa fa-check"></i><b>9.3.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#hierarchical-model"><i class="fa fa-check"></i><b>9.4</b> Hierarchical model</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#prior-calibration-1"><i class="fa fa-check"></i><b>9.4.1</b> Prior calibration</a></li>
<li class="chapter" data-level="9.4.2" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#the-stan-model-1"><i class="fa fa-check"></i><b>9.4.2</b> The <em>Stan</em> model</a></li>
<li class="chapter" data-level="9.4.3" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#results-1"><i class="fa fa-check"></i><b>9.4.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#some-code-used-to-estimate-the-models-1"><i class="fa fa-check"></i><b>9.5</b> Some code used to estimate the models</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#loading-the-data"><i class="fa fa-check"></i><b>9.5.1</b> Loading the data</a></li>
<li class="chapter" data-level="9.5.2" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#estimating-the-representative-agent-models"><i class="fa fa-check"></i><b>9.5.2</b> Estimating the representative agent models</a></li>
<li class="chapter" data-level="9.5.3" data-path="application-experience-weighted-attraction.html"><a href="application-experience-weighted-attraction.html#estimating-the-hierarchical-model"><i class="fa fa-check"></i><b>9.5.3</b> Estimating the hierarchical model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html"><i class="fa fa-check"></i><b>10</b> Application: Strategy Frequency Estimation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html#simplifying-the-individual-likelihood-functions"><i class="fa fa-check"></i><b>10.1</b> Simplifying the individual likelihood functions</a></li>
<li class="chapter" data-level="10.2" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html#example-experiment-dbf2011"><i class="fa fa-check"></i><b>10.2</b> Example experiment: <span class="citation">Dal Bó and Fréchette (2011)</span></a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html#the-sfem-with-homogeneous-trembles"><i class="fa fa-check"></i><b>10.2.1</b> The SFEM with homogeneous trembles</a></li>
<li class="chapter" data-level="10.2.2" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html#adding-heterogeneous-trembles-and-integrating-the-likelihood"><i class="fa fa-check"></i><b>10.2.2</b> Adding heterogeneous trembles and integrating the likelihood</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="application-strategy-frequency-estimation.html"><a href="application-strategy-frequency-estimation.html#r-code-to-do-these-estimations"><i class="fa fa-check"></i><b>10.3</b> <em>R</em> code to do these estimations</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html"><i class="fa fa-check"></i><b>11</b> Computing Quantal Response Equilibrium</a>
<ul>
<li class="chapter" data-level="11.1" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#overview-of-quantal-response-equilibrium"><i class="fa fa-check"></i><b>11.1</b> Overview of quantal response equilibrium</a></li>
<li class="chapter" data-level="11.2" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#computing-quantal-response-equilibrium-1"><i class="fa fa-check"></i><b>11.2</b> Computing Quantal Response Equilibrium</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#setting-up-the-problem"><i class="fa fa-check"></i><b>11.2.1</b> Setting up the problem</a></li>
<li class="chapter" data-level="11.2.2" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#a-predictor-corrector-algorithm"><i class="fa fa-check"></i><b>11.2.2</b> A predictor-corrector algorithm</a></li>
<li class="chapter" data-level="11.2.3" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#initial-conditions"><i class="fa fa-check"></i><b>11.2.3</b> Initial conditions</a></li>
<li class="chapter" data-level="11.2.4" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#algorithm-tuning"><i class="fa fa-check"></i><b>11.2.4</b> Algorithm tuning</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#the-predictor-corrector-algorithm-in-r"><i class="fa fa-check"></i><b>11.3</b> The predictor-corrector algorithm in <em>R</em></a></li>
<li class="chapter" data-level="11.4" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#some-example-games"><i class="fa fa-check"></i><b>11.4</b> Some example games</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#generalized-matching-pennies-ochs1995"><i class="fa fa-check"></i><b>11.4.1</b> Generalized matching pennies <span class="citation">(Ochs 1995)</span></a></li>
<li class="chapter" data-level="11.4.2" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#stag-hunt"><i class="fa fa-check"></i><b>11.4.2</b> Stag hunt</a></li>
<li class="chapter" data-level="11.4.3" data-path="computing-quantal-response-equilibrium.html"><a href="computing-quantal-response-equilibrium.html#n-player-volunteers-dilemma-imposing-symmetric-strategies"><i class="fa fa-check"></i><b>11.4.3</b> <span class="math inline">\(n\)</span>-player Volunteer’s Dilemma imposing symmetric strategies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><i class="fa fa-check"></i><b>12</b> Application: Quantal Response Equilibrium and the Volunteer’s Dilemma <span class="citation">(Goeree, Holt, and Smith 2017)</span></a>
<ul>
<li class="chapter" data-level="12.1" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#solving-logit-qre-and-estimating-the-model"><i class="fa fa-check"></i><b>12.1</b> Solving logit QRE and estimating the model</a></li>
<li class="chapter" data-level="12.2" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#adding-some-heterogeneity-1"><i class="fa fa-check"></i><b>12.2</b> Adding some heterogeneity</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#computing-quantal-response-equilibrium-with-heterogeneous-parameters"><i class="fa fa-check"></i><b>12.2.1</b> Computing quantal response equilibrium with heterogeneous parameters</a></li>
<li class="chapter" data-level="12.2.2" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#warm-glow-volunteering"><i class="fa fa-check"></i><b>12.2.2</b> Warm glow volunteering</a></li>
<li class="chapter" data-level="12.2.3" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#duplicate-aversion"><i class="fa fa-check"></i><b>12.2.3</b> Duplicate aversion</a></li>
<li class="chapter" data-level="12.2.4" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#results-2"><i class="fa fa-check"></i><b>12.2.4</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html"><a href="application-quantal-response-equilibrium-and-the-volunteers-dilemma-goeree2017.html#r-code-to-run-estimations"><i class="fa fa-check"></i><b>12.3</b> <em>R</em> code to run estimations</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html"><i class="fa fa-check"></i><b>13</b> Application: A Quantal Response Equilibrium with discrete types</a>
<ul>
<li class="chapter" data-level="13.1" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#example-dataset-and-models"><i class="fa fa-check"></i><b>13.1</b> Example dataset and models</a></li>
<li class="chapter" data-level="13.2" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#a-note-on-replication"><i class="fa fa-check"></i><b>13.2</b> A note on replication</a></li>
<li class="chapter" data-level="13.3" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#three-models-that-make-different-assumptions-about-bracketing"><i class="fa fa-check"></i><b>13.3</b> Three models that make different assumptions about bracketing</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#broad-bracketing-only"><i class="fa fa-check"></i><b>13.3.1</b> Broad bracketing only</a></li>
<li class="chapter" data-level="13.3.2" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#narrow-bracketing-only"><i class="fa fa-check"></i><b>13.3.2</b> Narrow bracketing only</a></li>
<li class="chapter" data-level="13.3.3" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#a-mixture-of-broad-and-narrow-bracketing"><i class="fa fa-check"></i><b>13.3.3</b> A mixture of broad and narrow bracketing</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#results-3"><i class="fa fa-check"></i><b>13.4</b> Results</a></li>
<li class="chapter" data-level="13.5" data-path="application-a-quantal-response-equilibrium-with-discrete-types.html"><a href="application-a-quantal-response-equilibrium-with-discrete-types.html#r-code-used-to-estimate-these-models"><i class="fa fa-check"></i><b>13.5</b> <em>R</em> code used to estimate these models</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="application-level-k-models.html"><a href="application-level-k-models.html"><i class="fa fa-check"></i><b>14</b> Application: Level-<span class="math inline">\(k\)</span> models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#data-and-game"><i class="fa fa-check"></i><b>14.1</b> Data and game</a></li>
<li class="chapter" data-level="14.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#the-level-k-model"><i class="fa fa-check"></i><b>14.2</b> The level-<span class="math inline">\(k\)</span> model</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#the-deterministic-component-of-the-model"><i class="fa fa-check"></i><b>14.2.1</b> The deterministic component of the model</a></li>
<li class="chapter" data-level="14.2.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#exact-and-probabilistic-play"><i class="fa fa-check"></i><b>14.2.2</b> Exact and probabilistic play</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="application-level-k-models.html"><a href="application-level-k-models.html#assigning-probabilities-to-types-for-each-participant-separately"><i class="fa fa-check"></i><b>14.3</b> Assigning probabilities to types for each participant separately</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#the-stan-program"><i class="fa fa-check"></i><b>14.3.1</b> The <em>Stan</em> program</a></li>
<li class="chapter" data-level="14.3.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#prior-calibration-2"><i class="fa fa-check"></i><b>14.3.2</b> Prior calibration</a></li>
<li class="chapter" data-level="14.3.3" data-path="application-level-k-models.html"><a href="application-level-k-models.html#results-4"><i class="fa fa-check"></i><b>14.3.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="application-level-k-models.html"><a href="application-level-k-models.html#doing-the-averaging-within-one-program"><i class="fa fa-check"></i><b>14.4</b> Doing the averaging within one program</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#the-stan-program-1"><i class="fa fa-check"></i><b>14.4.1</b> The <em>Stan</em> program</a></li>
<li class="chapter" data-level="14.4.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#results-5"><i class="fa fa-check"></i><b>14.4.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="application-level-k-models.html"><a href="application-level-k-models.html#a-mixture-model"><i class="fa fa-check"></i><b>14.5</b> A mixture model</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#stan-program"><i class="fa fa-check"></i><b>14.5.1</b> <em>Stan</em> program</a></li>
<li class="chapter" data-level="14.5.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#a-prior-for-psi"><i class="fa fa-check"></i><b>14.5.2</b> A prior for <span class="math inline">\(\psi\)</span></a></li>
<li class="chapter" data-level="14.5.3" data-path="application-level-k-models.html"><a href="application-level-k-models.html#results-6"><i class="fa fa-check"></i><b>14.5.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="application-level-k-models.html"><a href="application-level-k-models.html#a-mixture-over-levels-and-hierarchical-nuisance-parameters"><i class="fa fa-check"></i><b>14.6</b> A mixture over levels and hierarchical nuisance parameters</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#prior-calibration-3"><i class="fa fa-check"></i><b>14.6.1</b> Prior calibration</a></li>
<li class="chapter" data-level="14.6.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#stan-program-1"><i class="fa fa-check"></i><b>14.6.2</b> <em>Stan</em> program</a></li>
<li class="chapter" data-level="14.6.3" data-path="application-level-k-models.html"><a href="application-level-k-models.html#results-7"><i class="fa fa-check"></i><b>14.6.3</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="application-level-k-models.html"><a href="application-level-k-models.html#a-different-assumption-about-mixing"><i class="fa fa-check"></i><b>14.7</b> A different assumption about mixing</a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#stan-program-2"><i class="fa fa-check"></i><b>14.7.1</b> <em>Stan</em> program</a></li>
<li class="chapter" data-level="14.7.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#results-8"><i class="fa fa-check"></i><b>14.7.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="application-level-k-models.html"><a href="application-level-k-models.html#r-code-to-estimate-the-models"><i class="fa fa-check"></i><b>14.8</b> <em>R</em> code to estimate the models</a>
<ul>
<li class="chapter" data-level="14.8.1" data-path="application-level-k-models.html"><a href="application-level-k-models.html#participant-specific-estimation-conditional-on-k-with-bayesian-model-averaging"><i class="fa fa-check"></i><b>14.8.1</b> Participant-specific estimation conditional on <span class="math inline">\(k\)</span> with Bayesian model averaging</a></li>
<li class="chapter" data-level="14.8.2" data-path="application-level-k-models.html"><a href="application-level-k-models.html#participant-specific-estimation-with-a-prior-over-k"><i class="fa fa-check"></i><b>14.8.2</b> Participant-specific estimation with a prior over <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="14.8.3" data-path="application-level-k-models.html"><a href="application-level-k-models.html#mixture-model"><i class="fa fa-check"></i><b>14.8.3</b> Mixture model</a></li>
<li class="chapter" data-level="14.8.4" data-path="application-level-k-models.html"><a href="application-level-k-models.html#hierarchical-model-1"><i class="fa fa-check"></i><b>14.8.4</b> Hierarchical model</a></li>
<li class="chapter" data-level="14.8.5" data-path="application-level-k-models.html"><a href="application-level-k-models.html#mixture-model-with-beliefs-consistent-with-truncated-type-distribution"><i class="fa fa-check"></i><b>14.8.5</b> Mixture model with beliefs consistent with truncated type distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html"><i class="fa fa-check"></i><b>15</b> Application: Estimating risk preferences</a>
<ul>
<li class="chapter" data-level="15.1" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#example-dataset"><i class="fa fa-check"></i><b>15.1</b> Example dataset</a></li>
<li class="chapter" data-level="15.2" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#we-might-not-just-be-interested-in-the-parameters"><i class="fa fa-check"></i><b>15.2</b> We might not just be interested in the parameters</a></li>
<li class="chapter" data-level="15.3" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#introducing-some-important-models"><i class="fa fa-check"></i><b>15.3</b> Introducing some important models</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#expected-utility-theory"><i class="fa fa-check"></i><b>15.3.1</b> Expected utility theory</a></li>
<li class="chapter" data-level="15.3.2" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#rank-dependent-utility-quiggin1982"><i class="fa fa-check"></i><b>15.3.2</b> Rank-dependent utility <span class="citation">(Quiggin 1982)</span></a></li>
<li class="chapter" data-level="15.3.3" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#comparing-the-certainty-equivalents-estimated-using-eut-and-rdu"><i class="fa fa-check"></i><b>15.3.3</b> Comparing the certainty equivalents estimated using EUT and RDU</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#a-hierarchical-specification"><i class="fa fa-check"></i><b>15.4</b> A hierarchical specification</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#population-level-estimates"><i class="fa fa-check"></i><b>15.4.1</b> Population-level estimates</a></li>
<li class="chapter" data-level="15.4.2" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#participant-level-estimates"><i class="fa fa-check"></i><b>15.4.2</b> Participant-level estimates</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="application-estimating-risk-preferences.html"><a href="application-estimating-risk-preferences.html#r-code-used-to-estimate-these-models-1"><i class="fa fa-check"></i><b>15.5</b> <em>R</em> code used to estimate these models</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html"><i class="fa fa-check"></i><b>16</b> Application: Meta-analysis using (some of) the METARET data</a>
<ul>
<li class="chapter" data-level="16.1" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#data"><i class="fa fa-check"></i><b>16.1</b> Data</a></li>
<li class="chapter" data-level="16.2" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#a-basic-model"><i class="fa fa-check"></i><b>16.2</b> A basic model</a></li>
<li class="chapter" data-level="16.3" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#but-the-data-are-really-interval-valued"><i class="fa fa-check"></i><b>16.3</b> But the data are really interval-valued!</a></li>
<li class="chapter" data-level="16.4" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#heterogeneous-standard-deviations"><i class="fa fa-check"></i><b>16.4</b> Heterogeneous standard deviations</a></li>
<li class="chapter" data-level="16.5" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#student-t-distributions-because-why-not"><i class="fa fa-check"></i><b>16.5</b> Student-<span class="math inline">\(t\)</span> distributions, because why not?</a></li>
<li class="chapter" data-level="16.6" data-path="application-meta-analysis-using-some-of-the-metaret-data.html"><a href="application-meta-analysis-using-some-of-the-metaret-data.html#r-code-to-estimate-the-models-1"><i class="fa fa-check"></i><b>16.6</b> <em>R</em> code to estimate the models</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html"><i class="fa fa-check"></i><b>17</b> Application: Ranked choices and the Thurstonian model</a>
<ul>
<li class="chapter" data-level="17.1" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#the-thurstonian-model"><i class="fa fa-check"></i><b>17.1</b> The Thurstonian model</a></li>
<li class="chapter" data-level="17.2" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#computational-issues"><i class="fa fa-check"></i><b>17.2</b> Computational issues</a></li>
<li class="chapter" data-level="17.3" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#example-dataset-and-model-2"><i class="fa fa-check"></i><b>17.3</b> Example dataset and model</a></li>
<li class="chapter" data-level="17.4" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#a-representative-agent-model"><i class="fa fa-check"></i><b>17.4</b> A representative agent model</a></li>
<li class="chapter" data-level="17.5" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#a-hierarchical-model"><i class="fa fa-check"></i><b>17.5</b> A hierarchical model</a></li>
<li class="chapter" data-level="17.6" data-path="application-ranked-choices-and-the-thurstonian-model.html"><a href="application-ranked-choices-and-the-thurstonian-model.html#r-code-used-to-run-this"><i class="fa fa-check"></i><b>17.6</b> <em>R</em> code used to run this</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="links-to-data.html"><a href="links-to-data.html"><i class="fa fa-check"></i>Links to data</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Structural Bayesian Techniques for Experimental and Behavioral Economics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hierarchical-models" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Hierarchical models<a href="hierarchical-models.html#hierarchical-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="a-random-sample-of-participants-walks-into-your-lab" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> A random sample of participants walks into your lab<a href="hierarchical-models.html#a-random-sample-of-participants-walks-into-your-lab" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose that your goal was to estimate a parameter <span class="math inline">\(\theta_i\)</span> for every participant in your experiment. In an ideal world, they would come into your laboratory with <span class="math inline">\(\theta_i\)</span> stamped to their face, and all you would have to do to know it perfectly would be to briefly look at them, pay them a small show-up fee, take note of their <span class="math inline">\(\theta_i\)</span>, and send them on their way. Such ideal participants are a pipe dream, but what we <em>can</em> do is ask them to make decisions <span class="math inline">\(y_i\)</span> that reveal to us something about their <span class="math inline">\(\theta_i\)</span>. If we have a probabilistic model that relates <span class="math inline">\(y_i\)</span> to <span class="math inline">\(\theta_i\)</span>, and we have a prior for <span class="math inline">\(\theta_i\)</span>, then we can learn about <span class="math inline">\(\theta_i\)</span>. But <span class="math inline">\(i\)</span> is not the only participant who comes to the lab. <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span>, and <span class="math inline">\(l\)</span> do as well. In fact, we are fortunate enough to get <span class="math inline">\(n\)</span> of them! Is there anything we can learn about <span class="math inline">\(\theta_i\)</span> by studying the data from participants <span class="math inline">\(j\)</span>, <span class="math inline">\(k\)</span>, and <span class="math inline">\(l\)</span>? The answer to this is a definitive “yes”, if <span class="math inline">\(\theta_i\)</span>, <span class="math inline">\(\theta_j\)</span>, <span class="math inline">\(\theta_k\)</span>, and <span class="math inline">\(\theta_l\)</span> are all drawn from the same distribution. In economic experiments this is a reasonably good assumption, as participants are typically drawn from the same subject pool.</p>
<p>So <em>how</em> do we learn about <span class="math inline">\(\theta_i\)</span> from <span class="math inline">\(j\)</span>’s decisions? We note that <span class="math inline">\(\theta_i\)</span> and <span class="math inline">\(\theta_j\)</span> are both draws from the same distribution, and so decisions <span class="math inline">\(y_j\)</span> are informative of not just <span class="math inline">\(\theta_j\)</span>, but the parameters governing this <em>population-level distribution</em>, call them <span class="math inline">\(\mathcal P\)</span>. That is, knowing <span class="math inline">\(\mathcal P\)</span> helps us learn about <span class="math inline">\(\theta_j\)</span> because <span class="math inline">\(\mathcal P\)</span> is the prior we should have on <span class="math inline">\(\theta_i\)</span>, and <span class="math inline">\(y_j\)</span> tells us something about <span class="math inline">\(\theta_j\)</span>, which in turn tells us something about <span class="math inline">\(\mathcal P\)</span>. So even if we don’t care directly about <span class="math inline">\(\mathcal P\)</span>, <span class="math inline">\(j\)</span>’s decisions can help us learn about <span class="math inline">\(i\)</span>’s parameter, <em>if we let them</em>. Furthermore, learning about population-level parameters <span class="math inline">\(\mathcal P\)</span> might be more interesting to us as researches than whatever is going on at the individual level. These parameters allow us to extrapolate beyond the sample of participants we get, and make statements about our entire subject pool.</p>
<p>This is where the benefits of Bayesian estimation really start to be realized!</p>
<p>Up to this point we have focused solely on representative agent models and participant-specific models. All of this work has not been a waste, as these models are important stepping stones on the way to richer models, but it is these richer models that provide deeper insight into our data. In this chapter, we will be estimating <em>population-level parameters</em>. These are parameters that govern the distribution of (what are usually) our participants’ individual parameters. That is, if our economic model is about preferences, we will be estimating the <em>distribution</em> of preferences. This is an amazingly powerful tool.</p>
<p>We will do this by assuming that our data follows a <em>hierarchical</em> structure. By that I mean that we will assume that we can partition our data into chunks, and maybe even that we can further partition these chunks into sub-chunks. We will then add some structure to how these chunks are related to each other, and estimate these relationships. What we get out of this is a quantification of the heterogeneity that exists between these chunks, and if we have more than one level (i.e. chunks and sub-chunks), the relative contribution to heterogeneity of each level.</p>
</div>
<div id="the-anatomy-of-a-basic-hierarchical-model" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> The anatomy of a basic hierarchical model<a href="hierarchical-models.html#the-anatomy-of-a-basic-hierarchical-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the previous chapter, we estimated a participant’s parameters using just the data generated by that participant. Specifically, we focused on just their own data <span class="math inline">\(y_i\)</span>, while ignoring the data produced by all our other participants <span class="math inline">\(y_{-i}\)</span>. Just like these participant-specific models, we will continue to have a probabilistic model for the participant’s behavior, which we will denote as the likelihood <span class="math inline">\(p(y_i\mid\theta_i)\)</span>. However now we will further specify a <em>distribution</em> for <span class="math inline">\(\theta_i\)</span>. That is, we will assume that each participant’s <span class="math inline">\(\theta_i\)</span> is an independent draw from the population of potential participants:</p>
<p><span class="math display">\[
\theta_i\sim iid G(\mathcal P)
\]</span></p>
<p>where <span class="math inline">\(G\)</span> is the family of distribution we have chosen to model how the <span class="math inline">\(\theta_i\)</span>s are generated, and <span class="math inline">\(\mathcal P\)</span> are the parameters in the distribution <span class="math inline">\(G\)</span>. For example, probably the most popular hierarchical specification assumes that <span class="math inline">\(\theta_i\)</span> are drawn from a multivariate normal distribution, so <span class="math inline">\(\mathcal P=(\mu,\Sigma)\)</span> are the mean vector and variance-covariance matrix of this distribution. I will discuss the multivariate normal hierarchical model in much more detail below.</p>
<p>If we were lucky enough to just observe <span class="math inline">\(\theta_i\)</span>, then it would be a straightforward task estimating <span class="math inline">\(\mathcal P\)</span>. Instead though, we get data that are generated according to:</p>
<p><span class="math display">\[
y_i\sim g(\theta_i)
\]</span>
where <span class="math inline">\(g\)</span> is the family of distribution that we have chosen to model how our data <span class="math inline">\(y_i\)</span> are generated conditional on our participant’s parameter <span class="math inline">\(\theta_i\)</span>. Putting this together, we observe <span class="math inline">\(y_i\)</span>, which tells us something about <span class="math inline">\(\theta_i\)</span>, which tells us something about <span class="math inline">\(\mathcal P\)</span>.</p>
<p>Note that all we need to simulate this data-generating process is to specify <span class="math inline">\(\mathcal P\)</span>. That is, we can:</p>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(\theta_i\sim G(\mathcal P)\)</span>, then</li>
<li>Draw <span class="math inline">\(y_i\sim g(\theta_i)\)</span></li>
</ol>
<p>Therefore, our likelihood for a participant’s data can be defined as follows:</p>
<p><span class="math display">\[
\begin{aligned}
p(y_i,\theta_i\mid \mathcal P)&amp;=p(y_i\mid \theta_i,\mathcal P)p(\theta_i\mid \mathcal P)\\
&amp;=p(y_i\mid\theta_i)p(\theta_i\mid\mathcal P)
\end{aligned}
\]</span></p>
<p>where the second line follows if we assume that <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\mathcal P\)</span> are independent conditional on <span class="math inline">\(\theta_i\)</span>. In plainer English: once we know <span class="math inline">\(\theta_i\)</span>, <span class="math inline">\(\mathcal P\)</span> will tell us no more information about <span class="math inline">\(y_i\)</span>. The power of this assumption is that it allows us to think separately about how our data are generated given the participant’s parameters, (i.e. <span class="math inline">\(p(y_i\mid\theta_i)\)</span>), and how participants are distributed across the population (i.e. <span class="math inline">\(p(\theta_i\mid\mathcal P)\)</span>).</p>
<p>Conceptually, the hierarchical structure (a distribution for <span class="math inline">\(\theta_i\)</span>) is hopefully easy to grasp. However we have a practical problem: we still don’t know <span class="math inline">\(\theta_i\)</span>, so any expression that includes it cannot be feasibly used to evaluate our model’s likelihood. The next section will develop two techniques for doing this. The first, integrating the likelihood, is popular for Frequentist techniques, but may sometimes be useful in Bayesian applications too; and the second, data augmentation, is the typical Bayesian go-to for this problem, and lends itself especially to the Hamiltonian Monte Carlo of <em>Stan</em> <span class="citation">(<a href="#ref-Betancourt2015">Betancourt and Girolami 2015</a>)</span>.</p>
</div>
<div id="accounting-for-unobserved-heterogeneity" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Accounting for unobserved heterogeneity<a href="hierarchical-models.html#accounting-for-unobserved-heterogeneity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the hurdles I came accross when I started learning about hierarchical models was how to treat unobservable heterogeneity. For most of the models discussed in this book, this unobservable heterogeneity will mostly be in participant-specific parameters. This problem is not specific to Bayesian implementations of hierarchical models, but it is typically addressed differently depending on whether one adopts a Bayesian or Frequentist (maximum likelihood) approach. In both cases the models can make the same distributional assumptions about <span class="math inline">\(\theta\)</span>, but they are typically treated in very different ways.</p>
<p>While maximum likelihood techniques typically integrate out the unobserved heterogeneity <span class="math inline">\(\theta\)</span> and just focus on estimating the population-level parameters <span class="math inline">\(\mathcal P\)</span>, the Bayesian implementation typically jointly estimates <span class="math inline">\(\theta\)</span> alongside <span class="math inline">\(\mathcal P\)</span>. I include an introduction to both techniques, as I believe they can both be useful tools that might be the best option to you in some cases.</p>
<div id="the-last-time-you-will-integrate-the-likelihood-probably" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> The last time you will integrate the likelihood, probably<a href="hierarchical-models.html#the-last-time-you-will-integrate-the-likelihood-probably" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The typical maximum likelihood implementation of a hierarchical model uses maximum simulated likelihood to eliminate the participant-level parameters <span class="math inline">\(\theta\)</span> from the likelihood function. This technique in the context of economic experiments is discussed in Chapter 10 of <span class="citation">Moffatt (<a href="#ref-Moffatt2015">2015</a>)</span>, and is the implementation used in the hierarchical models estimated in, for example, <span class="citation">Conte, Hey, and Moffatt (<a href="#ref-Conte2011">2011</a>)</span>.</p>
<p>The likelihood of observing data <span class="math inline">\(y_i\)</span> conditional on only population-level parameters <span class="math inline">\(\mathcal P\)</span> can be approximated as:</p>
<p><span class="math display">\[
\begin{aligned}
p(y_i\mid \mathcal P)&amp;=\int_\Theta p(y_i,\theta\mid \mathcal P)\mathrm d\theta\\
&amp;=\int_\Theta p(y_i\mid \theta,\mathcal P)p(\theta\mid\mathcal P)\mathrm d\theta\\
&amp;=E_{\theta\mid\mathcal P}\left[p(y_i\mid\theta,\mathcal P)\right]\\
&amp;\approx\frac{1}{S}\sum_{s=1}^S p(y_i\mid \theta^s,\mathcal P),\quad \text{with:}\ \theta^s\sim iid G(\mathcal P)
\end{aligned}
\]</span></p>
<p>where the first equality follows because of the relationship between the marginal distribution <span class="math inline">\(y_i\mid \mathcal P\)</span> and the joint distribution <span class="math inline">\(y_i,\theta\mid \mathcal P\)</span>. The second inequality writes this joint distribution function as the product of a conditional and a marginal distribution.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> The third equality follows by recognizing that the expression in the second line is the expectation of <span class="math inline">\(p(y_i\mid \theta,\mathcal P)\)</span>, where <span class="math inline">\(\theta\mid\mathcal P\)</span> is the only random variable, and the approximation is a Monte Carlo integration of this expectation. This approximation can be made more efficient using Halton draws, which are discussed in Section 10.3 of <span class="citation">Moffatt (<a href="#ref-Moffatt2015">2015</a>)</span>.</p>
<p>What all of this means is that you can approximate the likelihood of the entire dataset as:</p>
<p><span class="math display">\[
p(y\mid\mathcal P)=\prod_{i=1}^np(y_i\mid\mathcal P)
\approx \prod_{i=1}^n\left(\frac{1}{S}\sum_{s=1}^Sp(y_i\mid \theta^s,\mathcal P)\right)
\]</span>
So the log-likelihood function, which is what we would pass to <em>Stan</em>, is approximated as:</p>
<p><span class="math display">\[
\log p(y\mid \mathcal P)\approx\sum_{i=1}^n\log\left(\frac1S\sum_{s=1}^Sp(y_i\mid \theta^s,\mathcal P)\right)
\]</span></p>
</div>
<div id="data-augmentation" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Data augmentation<a href="hierarchical-models.html#data-augmentation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The other technique for accounting for unobserved heterogeneity is called “data augmentation”, and basically comes down to jointly estimating the participant-specific parameters alongside the population-level parameters. This means specifying a posterior distribution in the following form:</p>
<p><span class="math display">\[
\begin{aligned}
p(\theta,\mathcal P\mid y)&amp;\propto p(y\mid \theta,\mathcal P)p(\theta,\mathcal P)\\
&amp;=p(y\mid \theta,\mathcal P)p(\theta\mid\mathcal P)p(\mathcal P)
\end{aligned}
\]</span></p>
<p>Note here the trade-off: we do not have to use Monte Carlo integration to approximate the likelihood (because we are jointly estimating <span class="math inline">\(\theta\)</span>), but we now have a whole lot more parameters to estimate! Specifically, while we do not have to evaluate each likelihood <span class="math inline">\(S\)</span> times for the Monte Carlo integration, we have to estimate all of the parameters in <span class="math inline">\(\theta\)</span>, not just <span class="math inline">\(\mathcal P\)</span>. As there will usually be at least one element in <span class="math inline">\(\theta\)</span> for every participant, this means that data augmentation can have us going from a few to many parameters very quickly.</p>
<p>Our final product is the posterior draws of <span class="math inline">\(\mathcal P\)</span> <em>and</em> <span class="math inline">\(\theta\)</span>, so not only do we have estimates of the population quantities, we also have estimates of the participants’ parameters. These estimates are referred to as <em>shrinkage</em> estimates because compared to their participant-specific counterparts from the previous section, they will be “shrunk” or pulled towards the center of the population distribution implied by <span class="math inline">\(\mathcal P\)</span>. This is a feature, not a bug: by jointly estimating <span class="math inline">\(\mathcal P\)</span> alongside <span class="math inline">\(\theta\)</span>, we are allowing our data to decide for us what an appropriate prior for <span class="math inline">\(\theta\)</span> is. In particular, this prior is the distribution implied by <span class="math inline">\(\mathcal P\)</span>, which since it is informed by the data, will most likely be more informative than our prior for the participant-specific counterpart.</p>
<p>The computational benefit of this method is that we only have to evaluate the likelihood once, instead of <span class="math inline">\(S\)</span> times if we were integrating it. My intuition for this, albeit only informed through a lot of trial and error trying both methods with both maximum likelihood and Bayesian techniques, is that these methods are common in their respective statistical philosophies for computational practicalities. Hamiltonian Monte Carlo, which is what <em>Stan</em> does, seems to scale well with the number of parameters in the model. Hence, adding a whole lot of participant-specific <span class="math inline">\(\theta\)</span>s to the bill of parameters that we need to estimate is not that much of an additional computational burden, especially when the <span class="math inline">\(\theta\)</span>s are well informed by the “prior” in the population distribution <span class="math inline">\(\mathcal P\)</span>. On the other hand, maximum likelihood does not scale so well with the number of parameters, and so Monte Carlo integration of the likelihood function will seriously cut down on the computational burden relative to data augmentation. This is not to say that there will not be times when you will want to integrate the likelihood for your Bayesian estimator. Rather, I would recommend trying data augmentation first, but if there are some pathologies in your likelihood function that make this difficult, integrating the likelihood might be something that you could try.</p>
</div>
</div>
<div id="a-multivariate-normal-hierarchical-model" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> A multivariate normal hierarchical model<a href="hierarchical-models.html#a-multivariate-normal-hierarchical-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Although there are many distributional families that you might want to use to model the distribution of your individual parameters, the multivariate normal distribution is a great place to start, and will get you a long way. For this, we will assume that our individual-level parameters <span class="math inline">\(\theta_i\)</span> follow a multivariate normal distribution:</p>
<p><span class="math display" id="eq:HierarchicalNormal">\[
\theta_i\sim iid N(\mu,\Sigma) \tag{6.1}
\]</span></p>
<p>Where if <span class="math inline">\(\theta_i\)</span> is a <span class="math inline">\(k\times 1\)</span> vector of parameters specific to participant <span class="math inline">\(i\)</span>, then <span class="math inline">\(\mu\)</span> is a <span class="math inline">\(k\times 1\)</span> mean vector of means, so:</p>
<p><span class="math display">\[
\mu_j=E(\theta_{i,j})
\]</span>
and <span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(k\times k\)</span> variance-covariance matrix: the diagonal elements of <span class="math inline">\(\Sigma\)</span> therefore correspond to the variances of each element of <span class="math inline">\(\theta_i\)</span>, and the off-diagonal components tell us the covariances. This specification therefore permits correlation between the participants’ parameters.</p>
<p>One thing you might be noticing about this specification (and the more general specification discussed above), is that the distribution in <a href="hierarchical-models.html#eq:HierarchicalNormal">(6.1)</a> almost looks like how we would specify a prior. This is certainly a helpful way to think about it: if we were instead estimating a participant-specific model using data from just that participant, <span class="math inline">\(\theta_i\sim N(\mu,\Sigma)\)</span> could exactly be our prior!<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> However instead of choosing <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> to express our belief about <span class="math inline">\(\theta_i\)</span>, we are instead assigning priors to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, then estimating these parameters. As such, instead of specifying priors for <span class="math inline">\(\theta_i\)</span>, as we did with the participant-specific estimation, we will be <em>estimating</em> what an appropriate prior for <span class="math inline">\(\theta_i\)</span> should be.</p>
<div id="decomposing-the-variance-covariance-matrix" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Decomposing the variance-covariance matrix<a href="hierarchical-models.html#decomposing-the-variance-covariance-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While it may be somewhat intuitive to assign a prior for a population mean parameter <span class="math inline">\(\mu\)</span>, I always find it difficult thinking about priors for variance-covariance matrices. For me, this is difficult because I don’t have good grasp of the implications of a prior for a matrix that must have some restrictions imposed on it (because it is a variance-covariance matrix). Fortunately, as documented in <a href="https://mc-stan.org/docs/stan-users-guide/multivariate-hierarchical-priors.html">Section 1.13 of the <em>Stan User’s Guide</em></a> <span class="citation">(<a href="#ref-StanUsersGuide">Stan Development Team 2022</a>)</span>, not only can we decompose this matrix into a vector of standard deviations, and a correlation matrix, two quantities I find <em>much</em> easier to think about, but we can assign priors to these quantities separately.</p>
<p>Specifically, note that our variance-covariance matrix <span class="math inline">\(\Sigma\)</span> can be decomposed into a <span class="math inline">\(k\times 1\)</span> vector <span class="math inline">\(\tau\)</span> of standard deviations, and a <span class="math inline">\(k\times k\)</span> correlation matrix <span class="math inline">\(\Omega\)</span>:</p>
<p><span class="math display">\[
\Sigma = \mathrm{diag}(\tau)\Omega\mathrm{diag}(\tau)
\]</span>
I find this immensely useful, because it permits us to think about the prior for <span class="math inline">\(\Sigma\)</span> in two stages:</p>
<ol style="list-style-type: decimal">
<li>Choose priors for the elements of <span class="math inline">\(\tau\)</span> to reflect our belief about the amount of heterogeneity in each element of <span class="math inline">\(\theta_i\)</span>.</li>
<li>Choose a prior for <span class="math inline">\(\Omega\)</span> to reflect our belief about how these parameters are correlated, without having to worry about the scale of these parameters.</li>
</ol>
<p>For the priors for <span class="math inline">\(\tau\)</span>, the <em>Stan User’s Guide</em> recommends a half Cauchy distribution. In the first example in this chapter, I discuss how we can use the cumulative density function of this distribution to work out how to assign appropriate priors.</p>
<p>For the correlation matrix <span class="math inline">\(\Omega\)</span>, the <em>Stan User’s Guide</em> recommends an LKJ prior, which has the form:</p>
<p><span class="math display">\[
\begin{aligned}
\Omega&amp;\sim \mathrm{LKJCorr}(\eta)
\iff p(\Omega\mid\eta)\propto \mathrm{det}(\Omega)^{\eta-1}
\end{aligned}
\]</span>
In order to investigate what this means for a correlation between two parameters, I wrote a <em>Stan</em> program to draw from this distribution, then varied the parameter <span class="math inline">\(\eta\)</span> and the matrix size <span class="math inline">\(k\)</span>:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb75-1"><a href="hierarchical-models.html#cb75-1" tabindex="-1"></a></span>
<span id="cb75-2"><a href="hierarchical-models.html#cb75-2" tabindex="-1"></a>data <span class="op">{</span></span>
<span id="cb75-3"><a href="hierarchical-models.html#cb75-3" tabindex="-1"></a>  <span class="dt">int</span><span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> k<span class="op">;</span> <span class="co">// size of correlation matrix</span></span>
<span id="cb75-4"><a href="hierarchical-models.html#cb75-4" tabindex="-1"></a>  real prior_corr<span class="op">;</span> <span class="co">// lkj prior on correlation matrix</span></span>
<span id="cb75-5"><a href="hierarchical-models.html#cb75-5" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb75-6"><a href="hierarchical-models.html#cb75-6" tabindex="-1"></a></span>
<span id="cb75-7"><a href="hierarchical-models.html#cb75-7" tabindex="-1"></a>parameters <span class="op">{</span></span>
<span id="cb75-8"><a href="hierarchical-models.html#cb75-8" tabindex="-1"></a>  corr_matrix<span class="op">[</span>k<span class="op">]</span> CORR<span class="op">;</span></span>
<span id="cb75-9"><a href="hierarchical-models.html#cb75-9" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb75-10"><a href="hierarchical-models.html#cb75-10" tabindex="-1"></a></span>
<span id="cb75-11"><a href="hierarchical-models.html#cb75-11" tabindex="-1"></a>model <span class="op">{</span></span>
<span id="cb75-12"><a href="hierarchical-models.html#cb75-12" tabindex="-1"></a>  CORR <span class="op">~</span> lkj_corr<span class="op">(</span>prior_corr<span class="op">);</span></span>
<span id="cb75-13"><a href="hierarchical-models.html#cb75-13" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Then I simulated its distribution for a few values of <span class="math inline">\(k\)</span> and <span class="math inline">\(\eta\)</span>:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="hierarchical-models.html#cb76-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb76-2"><a href="hierarchical-models.html#cb76-2" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb76-3"><a href="hierarchical-models.html#cb76-3" tabindex="-1"></a>  <span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">TRUE</span>)</span>
<span id="cb76-4"><a href="hierarchical-models.html#cb76-4" tabindex="-1"></a>  <span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb76-5"><a href="hierarchical-models.html#cb76-5" tabindex="-1"></a></span>
<span id="cb76-6"><a href="hierarchical-models.html#cb76-6" tabindex="-1"></a><span class="co"># values to loop over  </span></span>
<span id="cb76-7"><a href="hierarchical-models.html#cb76-7" tabindex="-1"></a>K<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>) <span class="co"># correlation matrix size</span></span>
<span id="cb76-8"><a href="hierarchical-models.html#cb76-8" tabindex="-1"></a>PRIOR_CORR<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fl">0.25</span>,<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">8</span>) <span class="co"># lkj prior parameter</span></span>
<span id="cb76-9"><a href="hierarchical-models.html#cb76-9" tabindex="-1"></a></span>
<span id="cb76-10"><a href="hierarchical-models.html#cb76-10" tabindex="-1"></a>CorrSim<span class="ot">&lt;-</span><span class="fu">tibble</span>()</span>
<span id="cb76-11"><a href="hierarchical-models.html#cb76-11" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> K) {</span>
<span id="cb76-12"><a href="hierarchical-models.html#cb76-12" tabindex="-1"></a>  <span class="cf">for</span> (prior_corr <span class="cf">in</span> PRIOR_CORR) {</span>
<span id="cb76-13"><a href="hierarchical-models.html#cb76-13" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">paste</span>(k,prior_corr))</span>
<span id="cb76-14"><a href="hierarchical-models.html#cb76-14" tabindex="-1"></a>    dStan<span class="ot">&lt;-</span><span class="fu">list</span>(<span class="at">k=</span>k,<span class="at">prior_corr=</span>prior_corr)</span>
<span id="cb76-15"><a href="hierarchical-models.html#cb76-15" tabindex="-1"></a>    Fit<span class="ot">&lt;-</span><span class="fu">stan</span>(<span class="st">&quot;Code/Hierarchical/lkj_corr.stan&quot;</span>,<span class="at">data=</span>dStan,<span class="at">seed=</span><span class="dv">42</span>)</span>
<span id="cb76-16"><a href="hierarchical-models.html#cb76-16" tabindex="-1"></a>    tmp<span class="ot">&lt;-</span><span class="fu">tibble</span>(</span>
<span id="cb76-17"><a href="hierarchical-models.html#cb76-17" tabindex="-1"></a>        <span class="at">prior_corr =</span> prior_corr,</span>
<span id="cb76-18"><a href="hierarchical-models.html#cb76-18" tabindex="-1"></a>        <span class="at">k =</span> k,</span>
<span id="cb76-19"><a href="hierarchical-models.html#cb76-19" tabindex="-1"></a>        <span class="at">corr =</span> <span class="fu">extract</span>(Fit)<span class="sc">$</span>CORR[,<span class="dv">1</span>,<span class="dv">2</span>]</span>
<span id="cb76-20"><a href="hierarchical-models.html#cb76-20" tabindex="-1"></a>    )</span>
<span id="cb76-21"><a href="hierarchical-models.html#cb76-21" tabindex="-1"></a>    CorrSim<span class="ot">&lt;-</span><span class="fu">rbind</span>(CorrSim,tmp)</span>
<span id="cb76-22"><a href="hierarchical-models.html#cb76-22" tabindex="-1"></a>    </span>
<span id="cb76-23"><a href="hierarchical-models.html#cb76-23" tabindex="-1"></a>  }</span>
<span id="cb76-24"><a href="hierarchical-models.html#cb76-24" tabindex="-1"></a>}</span>
<span id="cb76-25"><a href="hierarchical-models.html#cb76-25" tabindex="-1"></a></span>
<span id="cb76-26"><a href="hierarchical-models.html#cb76-26" tabindex="-1"></a><span class="fu">saveRDS</span>(CorrSim,<span class="st">&quot;Outputs/Hierarchical/Hierarchica_lkj_corr.Rds&quot;</span>)</span></code></pre></div>
<p>As the LKJ correlation distribution is symmetric, we only need to look at one of the correlations to get the picture, so here it is:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="hierarchical-models.html#cb77-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb77-2"><a href="hierarchical-models.html#cb77-2" tabindex="-1"></a>corr<span class="ot">&lt;-</span><span class="fu">readRDS</span>(<span class="st">&quot;Outputs/Hierarchical/Hierarchica_lkj_corr.Rds&quot;</span>)</span>
<span id="cb77-3"><a href="hierarchical-models.html#cb77-3" tabindex="-1"></a>(</span>
<span id="cb77-4"><a href="hierarchical-models.html#cb77-4" tabindex="-1"></a>  <span class="fu">ggplot</span>(corr,<span class="fu">aes</span>(<span class="at">x=</span>corr))</span>
<span id="cb77-5"><a href="hierarchical-models.html#cb77-5" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">stat_density</span>(<span class="at">alpha=</span><span class="fl">0.7</span>)</span>
<span id="cb77-6"><a href="hierarchical-models.html#cb77-6" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">facet_grid</span>(<span class="fu">paste</span>(<span class="st">&quot;eta =&quot;</span>,prior_corr)<span class="sc">~</span><span class="fu">paste</span>(<span class="st">&quot;k =&quot;</span>,k))</span>
<span id="cb77-7"><a href="hierarchical-models.html#cb77-7" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">theme_bw</span>()</span>
<span id="cb77-8"><a href="hierarchical-models.html#cb77-8" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:HierarchicalLKJ"></span>
<img src="index_files/figure-html/HierarchicalLKJ-1.png" alt="Simulated distributions of correlations from the LKJ distribution. $k$ is the matrix size, and $\eta$ is the parameter in the LKJ distribution." width="672" />
<p class="caption">
Figure 6.1: Simulated distributions of correlations from the LKJ distribution. <span class="math inline">\(k\)</span> is the matrix size, and <span class="math inline">\(\eta\)</span> is the parameter in the LKJ distribution.
</p>
</div>
<p>Figure <a href="hierarchical-models.html#fig:HierarchicalLKJ">6.1</a> confirms main features of the LKH distribution, as outlined in Section 1.13 of the <em>Stan User’s Guide</em></p>
<blockquote>
<p>The basic behavior of the LKJ correlation distribution is similar to that of a beta distribution. For <span class="math inline">\(\eta=1\)</span>, the result is a uniform distribution. Despite being the identity over correlation matrices, the marginal distribution over the entries in that matrix (i.e., the correlations) is not uniform between -1 and 1. Rather, it concentrates around zero as the dimensionality increases due to the complex constraints. For <span class="math inline">\(\eta&gt;1\)</span>, the density increasingly concentrates mass around the unit matrix, i.e., favoring less correlation. For <span class="math inline">\(\eta&lt;1\)</span>, it increasingly concentrates mass in the other direction, i.e., favoring more correlation.</p>
</blockquote>
<p>That is, for small correlation matrices (say, <span class="math inline">\(k=2\)</span>), the distribution is more spread out, and the modes are more pronounced when <span class="math inline">\(\eta&lt;1\)</span>. Visually, it seems like the matrix size <span class="math inline">\(k\)</span> is less important for larger values of <span class="math inline">\(\eta\)</span>. All of this is to say, we probably want to choose an <span class="math inline">\(\eta&gt;1\)</span> (which is also recommended by the <em>Guide</em>), but we will also want to choose <span class="math inline">\(\eta\)</span> differently depending on the number of participant-level parameters <span class="math inline">\(k\)</span> we have in our model.</p>
<p>Section 1.13 of the <em>Stan User’s Guide</em><a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> also suggests using Cholesky factorization to further decompose the correlation matrix <span class="math inline">\(\Omega\)</span>. That is, we can represent <span class="math inline">\(\Omega\)</span> as the outer product of a triangular matrix <span class="math inline">\(L_\Omega\)</span> with itself:</p>
<p><span class="math display">\[
\Omega = L_\Omega L_\Omega^\top
\]</span></p>
<p>This is particularly useful because we can then express our participant-level parameters as a linear combination of standard normal random variables:</p>
<p><span class="math display">\[
\begin{aligned}
\theta_i&amp;=\mu+\mathrm{diag}(\tau)L_\Omega z_i\\
z_{i,j}&amp;\sim iid N(0,1)
\end{aligned}
\]</span></p>
<p>This representation speeds up computation because evaluating the multivariate normal density and the LKJ prior both require factorization. By re-parameterizing the model in terms of the already factorized values, we avoid this factorization. This also permits writing the whole collection of individual parameters <span class="math inline">\(\theta=(\theta_1,\theta_2,\ldots,\theta_n)\)</span> as one big matrix operation involving the already factorized parameters, and standard normals (which are very fast to simulate):</p>
<p><span class="math display">\[
\begin{aligned}
\theta&amp;=\mu 1_n^\top+\mathrm{diag}(\tau)L_\Omega z \\
z_{j,i}&amp;\sim iidN(0,1)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(z\)</span> is a <span class="math inline">\(k\times n\)</span> matrix of standard normals.</p>
<p>All of these modifications might make your model less intuitive to read, but they will make it easier for <em>Stan</em> to simulate your posterior quickly and without errors. What we will end up with is a model whose actual parameters are <span class="math inline">\(\{\mu,\tau,L_\Omega,z\}\)</span> instead of <span class="math inline">\(\{\mu,\Sigma,\theta\}\)</span>, however we will always be able to generate the (hopefully) more interpretable parameters of <span class="math inline">\(\Sigma\)</span>, <span class="math inline">\(\Omega\)</span>, and <span class="math inline">\(\theta\)</span>, because there is a deterministic relationship between them.</p>
</div>
<div id="transformed-parameters-and-normal-distributions" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Transformed parameters and normal distributions<a href="hierarchical-models.html#transformed-parameters-and-normal-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One restriction that applies when estimating a hierarchical model with a multivariate normal distribution of individual-level parameters is that these individual-level parameters must be able to take on any real number. This is not a problem for, say, the risk-aversion parameter <span class="math inline">\(r\)</span> in the CRRA utility function <span class="math inline">\(u_i(x)=\frac{x^{1-r_i}}{1-r_i}\)</span>, however there are many other cases where our models’ parameters must be resrticted to only a subset of the real number line. For these parameters, we are going to have to transform them before they enter the model. That is, instead of estimating (say) logit choice precision parameter <span class="math inline">\(\lambda\)</span>, which must be positive, we could estimate <span class="math inline">\(\log\lambda\)</span>, as <span class="math inline">\(\log(\cdot)\)</span> takes a positive real number, and maps it onto the real number line. Other times, our parameters need to be restricted to the unit interval. In these cases one can use the inverse logit (<span class="math inline">\(\log(x)-\log(1-x)\)</span>) or inverse normal cumulative density <span class="math inline">\(\Phi^{-1}(x)\)</span>.</p>
</div>
</div>
<div id="example-again-with-bfs2019" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Example: again with <span class="citation">Bruhin, Fehr, and Schunk (<a href="#ref-BFS2019">2019</a>)</span><a href="hierarchical-models.html#example-again-with-bfs2019" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="hierarchical-models.html#cb78-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb78-2"><a href="hierarchical-models.html#cb78-2" tabindex="-1"></a></span>
<span id="cb78-3"><a href="hierarchical-models.html#cb78-3" tabindex="-1"></a>d1<span class="ot">&lt;-</span>(<span class="fu">read.csv</span>(<span class="st">&quot;Data/BFS2019_choices_exp1.csv&quot;</span>)</span>
<span id="cb78-4"><a href="hierarchical-models.html#cb78-4" tabindex="-1"></a>     <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">experiment=</span><span class="dv">1</span>)</span>
<span id="cb78-5"><a href="hierarchical-models.html#cb78-5" tabindex="-1"></a>)</span>
<span id="cb78-6"><a href="hierarchical-models.html#cb78-6" tabindex="-1"></a>d2<span class="ot">&lt;-</span>(<span class="fu">read.csv</span>(<span class="st">&quot;Data/BFS2019_choices_exp2.csv&quot;</span>)</span>
<span id="cb78-7"><a href="hierarchical-models.html#cb78-7" tabindex="-1"></a>     <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">experiment=</span><span class="dv">2</span>)    </span>
<span id="cb78-8"><a href="hierarchical-models.html#cb78-8" tabindex="-1"></a>)</span>
<span id="cb78-9"><a href="hierarchical-models.html#cb78-9" tabindex="-1"></a>D<span class="ot">&lt;-</span>(<span class="fu">rbind</span>(d1,d2)</span>
<span id="cb78-10"><a href="hierarchical-models.html#cb78-10" tabindex="-1"></a>     <span class="co"># Just use the dictator game data</span></span>
<span id="cb78-11"><a href="hierarchical-models.html#cb78-11" tabindex="-1"></a>     <span class="sc">|&gt;</span> <span class="fu">filter</span>(dg<span class="sc">==</span><span class="dv">1</span>)  </span>
<span id="cb78-12"><a href="hierarchical-models.html#cb78-12" tabindex="-1"></a>     <span class="sc">|&gt;</span> <span class="fu">mutate</span>(</span>
<span id="cb78-13"><a href="hierarchical-models.html#cb78-13" tabindex="-1"></a>       <span class="at">self_alloc =</span> <span class="fu">ifelse</span>(choice_x<span class="sc">==</span><span class="dv">1</span>,self_x,self_y),</span>
<span id="cb78-14"><a href="hierarchical-models.html#cb78-14" tabindex="-1"></a>       <span class="at">other_alloc =</span> <span class="fu">ifelse</span>(choice_x<span class="sc">==</span><span class="dv">1</span>,other_x,other_y)</span>
<span id="cb78-15"><a href="hierarchical-models.html#cb78-15" tabindex="-1"></a>     )</span>
<span id="cb78-16"><a href="hierarchical-models.html#cb78-16" tabindex="-1"></a>)</span></code></pre></div>
<p>I will begin with again analyzing the modified dictator game decisions in <span class="citation">Bruhin, Fehr, and Schunk (<a href="#ref-BFS2019">2019</a>)</span>, which I introduced in the previous chapter. Recall that in this experiment, 174 participants each made 78 pairwise choices over allocations of money between themself and another participant. As with the previous chapter, I will stick with the <span class="citation">Fehr and Schmidt (<a href="#ref-FS1999">1999</a>)</span> model of inequality-aversion as the deterministic economic model:</p>
<p><span class="math display">\[
U(\pi_1,\pi_2;\alpha_i,\beta_i)=\pi_1-\alpha_i\max\{\pi_2-\pi_1,0\}-\beta_i\max\{\pi_1-\pi_2\}
\]</span>
and the logistic choice model to make it a probabilistic model that permits a likelihood representation:</p>
<p><span class="math display">\[
X_{i,t}\mid \theta,\mu,\Sigma\sim\mathrm{Bernoulli}\left(\Lambda\left(\lambda_i\left(
U(\pi^X_1,\pi^X_2;\alpha_i,\beta_i)-U(\pi^Y_1,\pi^Y_2;\alpha_i,\beta_i)
\right)\right)\right)
\]</span></p>
<p>While this statement of the model is almost identical to how I made it in the previous chapter, there are some changes in notation that need to be noted. Firstly, I have explicitly put an <span class="math inline">\(i\)</span> subscript on the individual-level parameters <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(\beta_i\)</span>, and <span class="math inline">\(\lambda_i\)</span>. This is to make it clear that each participant <span class="math inline">\(i\)</span> has their own parameters. For ease of notation here, I have lumped all of these parameters together into <span class="math inline">\(\theta\)</span>, so that we can talk about the population distribution more compactly. That is:</p>
<p><span class="math display">\[
\theta_i=\begin{pmatrix}\alpha_i&amp;\beta_i&amp;\log\lambda_i\end{pmatrix}^\top
\]</span>
where taking the log of <span class="math inline">\(\lambda\)</span> ensures that all elements of the (transformed) parameter vector <span class="math inline">\(\theta\)</span> can take on any real number. The above sampling statement also conditions on the population level parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, however we do not see any elements of these parameters on the right-hand side of the sampling statement. This is because it is assumed that <span class="math inline">\(\theta\)</span>, and in fact just <span class="math inline">\(\theta_i\)</span>, contains all of the information about the distribution of choices <span class="math inline">\(X_{i,t}\)</span> for participant <span class="math inline">\(i\)</span>. Put differently, once we know a participant’s parameters <span class="math inline">\(\theta_i\)</span>, the population distribution does not tell us anything more about the distribution of their choices.</p>
<p>To fully specify the likelihood, we need to specify how the individual-level parameters <span class="math inline">\(\theta_i\)</span> are generated by the population-level parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>. Let’s specify an independent multivariate normal distribution for <span class="math inline">\(\theta_i\)</span>:</p>
<p><span class="math display">\[
\theta_i\sim iid N(\mu,\Sigma)
\]</span>
where <span class="math inline">\(\mu\)</span> is the population mean of <span class="math inline">\(\theta_i\)</span> and <span class="math inline">\(\Sigma\)</span> is the population variance-covariance matrix of <span class="math inline">\(\theta_i\)</span>.</p>
<p>At this point, note that if I told you the population level parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>, then you would be able to simulate data from the experiment. Specifically, you would draw <span class="math inline">\(n\)</span> <span class="math inline">\(\theta_i\)</span>s from the multivariate normal, and then use these <span class="math inline">\(\theta_i\)</span>s to simulate the binary choices <span class="math inline">\(\{X_{i,t}\}_{i=1,t=1}^{n,T}\)</span>. This means we have all of the information needed to specify the likelihood. What remains is to choose priors for the population-level parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span>. As building up priors on variance-covariance matrices can be daunting if handled in one go, I will first take you through a model that assumes that the individual-level parameters are uncorrelated. Fortunately this for us, this is a really useful stepping stone for the correlated model, because <em>Stan</em> lets us decompose a variance-covariance matrix into a vector of standard deviations and a correlation matrix.</p>
<div id="no-correlation-between-individual-level-parameters" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> No correlation between individual-level parameters<a href="hierarchical-models.html#no-correlation-between-individual-level-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose to begin with that our individual-level parameters are not correlated with each other. We can therefore re-write the hierarchical structure of the model as:</p>
<p><span class="math display">\[
\begin{aligned}
\theta_{i,\alpha}&amp;\sim iid N(\mu_\alpha,\tau_\alpha^2)\\
\theta_{i,\beta}&amp;\sim iid N(\mu_\beta,\tau_\beta^2)\\
\theta_{i,\lambda}&amp;\sim iid N(\mu_\lambda,\tau_\lambda^2)\\
\end{aligned}
\]</span></p>
<div id="a-quick-prior-calibration" class="section level4 hasAnchor" number="6.5.1.1">
<h4><span class="header-section-number">6.5.1.1</span> A quick prior calibration<a href="hierarchical-models.html#a-quick-prior-calibration" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Here it is appropriate to assign normal priors to the mean parameters, and half Cauchy priors (i.e. truncated to be positive only) to the standard deviations. As with the example using this dataset in the previous chapter, let’s start by selecting a prior for <span class="math inline">\(\lambda_i\)</span>. However this time, we need to specify priors for the parameters that govern the distribution of <span class="math inline">\(\lambda_i\)</span>. Here, I decided to use the following prior for <span class="math inline">\(\lambda\)</span> in the representative agent model:</p>
<p><span class="math display">\[
\log\lambda\sim N(-5.76,2.11^2)
\]</span>
It seems reasonable that we will want the prior mean of <span class="math inline">\(\mu_\lambda\)</span> to be in the same location, so this leaves us with working out an appropriate prior standard deviation for <span class="math inline">\(\mu_\lambda\)</span>.
Recall that in this previous example, I used the model’s predicted probability for a selfish participant as a gauge for where the economically interesting values of <span class="math inline">\(\lambda\)</span> were. Again, we can then limit ourselves to looking at twelve different payoff differences:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="hierarchical-models.html#cb79-1" tabindex="-1"></a>d<span class="ot">&lt;-</span>(D</span>
<span id="cb79-2"><a href="hierarchical-models.html#cb79-2" tabindex="-1"></a>    <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">absDiff =</span> <span class="fu">abs</span>(self_x<span class="sc">-</span>self_y))</span>
<span id="cb79-3"><a href="hierarchical-models.html#cb79-3" tabindex="-1"></a>    <span class="sc">|&gt;</span> dplyr<span class="sc">::</span><span class="fu">select</span>(absDiff)</span>
<span id="cb79-4"><a href="hierarchical-models.html#cb79-4" tabindex="-1"></a>    <span class="sc">|&gt;</span> <span class="fu">unique</span>()</span>
<span id="cb79-5"><a href="hierarchical-models.html#cb79-5" tabindex="-1"></a>    )</span>
<span id="cb79-6"><a href="hierarchical-models.html#cb79-6" tabindex="-1"></a>d<span class="sc">$</span>absDiff <span class="sc">|&gt;</span> <span class="fu">print</span>()</span></code></pre></div>
<pre><code>##  [1] 140 200 380 240 120  80  40 280 180   0 160 360</code></pre>
<p>As this problem will be a bit more complicated, I will just focus on the median value of these differences:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="hierarchical-models.html#cb81-1" tabindex="-1"></a>(dMedian<span class="ot">&lt;-</span>d<span class="sc">$</span>absDiff <span class="sc">|&gt;</span> <span class="fu">median</span>())</span></code></pre></div>
<pre><code>## [1] 170</code></pre>
<p>Furthermore, since we are taking the log of <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\exp(\mu_\lambda)\)</span> gives us the <em>median</em> of the distribution of the predicted choice probability. Figure <a href="hierarchical-models.html#fig:HierarchicalBFSCalibrateLambda">6.2</a> shows how the distribution of this choice probability, summarized by the median, 2.5th, 25th, 75th, and 97.5th percentiles, changes as we change the prior standard deviation of <span class="math inline">\(\mu_\lambda\)</span>. Here, we don’t want to set the prior standard deviation too small, because otherwise it would influence our posterior too much. On the the other hand, we don’t want to set it too large, either, because this could mean we are searching for solutions of our model in unlikely regions of the parameter space. For me, choosing a prior standard deviation of one find this happy middle ground. That is, I will go with:</p>
<p><span class="math display">\[
\mu_\lambda\sim N(-5.76,1^2)
\]</span></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="hierarchical-models.html#cb83-1" tabindex="-1"></a>lambdaCheck<span class="ot">&lt;-</span>(</span>
<span id="cb83-2"><a href="hierarchical-models.html#cb83-2" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">priorSD =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="at">length=</span><span class="dv">100</span>))</span>
<span id="cb83-3"><a href="hierarchical-models.html#cb83-3" tabindex="-1"></a>      <span class="sc">|&gt;</span> <span class="fu">mutate</span>( </span>
<span id="cb83-4"><a href="hierarchical-models.html#cb83-4" tabindex="-1"></a>        <span class="at">PrMedian =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">5.76</span>)<span class="sc">*</span>dMedian)),</span>
<span id="cb83-5"><a href="hierarchical-models.html#cb83-5" tabindex="-1"></a>        <span class="at">Pr975    =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">5.76</span><span class="sc">+</span>priorSD<span class="sc">*</span><span class="fl">1.96</span>)<span class="sc">*</span>dMedian)),</span>
<span id="cb83-6"><a href="hierarchical-models.html#cb83-6" tabindex="-1"></a>        <span class="at">Pr025    =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">5.76</span><span class="sc">-</span>priorSD<span class="sc">*</span><span class="fl">1.96</span>)<span class="sc">*</span>dMedian)),</span>
<span id="cb83-7"><a href="hierarchical-models.html#cb83-7" tabindex="-1"></a>        <span class="at">Pr750    =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">5.76</span><span class="sc">+</span>priorSD<span class="sc">*</span><span class="fl">0.67</span>)<span class="sc">*</span>dMedian)),</span>
<span id="cb83-8"><a href="hierarchical-models.html#cb83-8" tabindex="-1"></a>        <span class="at">Pr250    =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>(<span class="sc">-</span><span class="fl">5.76</span><span class="sc">-</span>priorSD<span class="sc">*</span><span class="fl">0.67</span>)<span class="sc">*</span>dMedian)),</span>
<span id="cb83-9"><a href="hierarchical-models.html#cb83-9" tabindex="-1"></a>        )</span>
<span id="cb83-10"><a href="hierarchical-models.html#cb83-10" tabindex="-1"></a>)</span>
<span id="cb83-11"><a href="hierarchical-models.html#cb83-11" tabindex="-1"></a></span>
<span id="cb83-12"><a href="hierarchical-models.html#cb83-12" tabindex="-1"></a>(</span>
<span id="cb83-13"><a href="hierarchical-models.html#cb83-13" tabindex="-1"></a>  <span class="fu">ggplot</span>(lambdaCheck,<span class="fu">aes</span>(<span class="at">x=</span>priorSD,<span class="at">y=</span>PrMedian))</span>
<span id="cb83-14"><a href="hierarchical-models.html#cb83-14" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_path</span>()</span>
<span id="cb83-15"><a href="hierarchical-models.html#cb83-15" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>Pr975,<span class="at">ymin=</span>Pr025),<span class="at">alpha=</span><span class="fl">0.2</span>)</span>
<span id="cb83-16"><a href="hierarchical-models.html#cb83-16" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>Pr750,<span class="at">ymin=</span>Pr250),<span class="at">alpha=</span><span class="fl">0.4</span>)</span>
<span id="cb83-17"><a href="hierarchical-models.html#cb83-17" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">theme_bw</span>()</span>
<span id="cb83-18"><a href="hierarchical-models.html#cb83-18" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">ylab</span>(<span class="st">&quot;median probability of choosing the option with the greatest utility&quot;</span>)</span>
<span id="cb83-19"><a href="hierarchical-models.html#cb83-19" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">xlab</span>(<span class="st">&quot;prior standard deviation of the population mean parameter for \u03bb&quot;</span>)</span>
<span id="cb83-20"><a href="hierarchical-models.html#cb83-20" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:HierarchicalBFSCalibrateLambda"></span>
<img src="index_files/figure-html/HierarchicalBFSCalibrateLambda-1.png" alt="A plot of the distribution of predicted choice probabilities that will help us calibrate the priors for choice precision." width="672" />
<p class="caption">
Figure 6.2: A plot of the distribution of predicted choice probabilities that will help us calibrate the priors for choice precision.
</p>
</div>
<p>Figure <a href="hierarchical-models.html#fig:HierarchicalBFSCalibrateLambda">6.2</a> will also be helpful to us in choosing a prior for <span class="math inline">\(\tau_\lambda\)</span>, the standard deviation of <span class="math inline">\(\log\lambda_i\)</span>. Firstly, since I have limited myself to priors of the form:</p>
<p><span class="math display">\[
\tau_\lambda\sim \mathrm{Cauchy}^+(0,g)
\]</span></p>
<p>it is informative to know that the cumulative distribution function of <span class="math inline">\(\tau_\lambda\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
F(x)&amp;=\frac{2}{\pi}\mathrm{arctan}\left(\frac{x}{g}\right)I(x\geq0)
\end{aligned}
\]</span>
and so we can write the inverse cumulative density function as:</p>
<p><span class="math display">\[
F^{-1}(p)=g\tan \left(\frac{\pi p}{2}\right)
\]</span></p>
<p>so the 95th percentile of the distribution is <span class="math inline">\(F^{-1}(0.95)=g\tan(0.95\pi/2)\approx 12.7g\)</span>. Figure <a href="hierarchical-models.html#fig:HierarchicalBFSCalibrateLambda">6.2</a> shows us, if we fix <span class="math inline">\(\mu_\lambda\)</span> to its prior median of <span class="math inline">\(-5.76\)</span>, what the implications of different values of <span class="math inline">\(\tau_\lambda\)</span> are. That is, we can re-label the horizontal axis as “<span class="math inline">\(\tau_\lambda\)</span>”, and the vertical axis as “distribution of choice probabilities if <span class="math inline">\(\mu_\lambda=-5.76\)</span>”. Since for <span class="math inline">\(\tau_\lambda&gt;3\)</span> the interquartile range of the distribution of this choice probability (dark shaded region) takes up almost all of the vertical distance, these seem like unlikely values. Therefore I will calibrate the prior so <span class="math inline">\(\tau_\lambda=3\)</span> is the 95th percentile of its distribution. Therefore <span class="math inline">\(g=3/12.7\approx0.24\)</span>, so:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_\lambda&amp;\sim N(-5.76,1^2)\\
\tau_\lambda&amp;\sim \mathrm{Cauchy}^+(0,0.24)
\end{aligned}
\]</span></p>
<p>For the priors for the parameters governing the distributions of <span class="math inline">\(\alpha_i\)</span> and <span class="math inline">\(\beta_i\)</span>, I will keep them centered on zero. This means that I am looking to fill the blanks in the following distributions:</p>
<p><span class="math display">\[
\mu_\alpha\sim N(0,s^2),\quad \tau_\alpha\sim \mathrm{Cauchy}^+(0,g)
\]</span>
and similarly for <span class="math inline">\(\mu_\beta\)</span>, and <span class="math inline">\(\tau_\beta\)</span>. While in the representative agent model I calibrated the priors for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> so that 75% of the prior distribution was in the range <span class="math inline">\((-1,1)\)</span>, this would put too much mass outside this region for their population means: we should expect there to be less prior uncertainty in <span class="math inline">\(\mu_\alpha\)</span> than in <span class="math inline">\(\alpha\)</span>. This is because <span class="math inline">\(\mu_\alpha\)</span> is a measure of central tendency for <span class="math inline">\(\alpha_i\)</span>, and so it seems reasonable that prior to observing the data, we should be more certain about <span class="math inline">\(\mu_\alpha\)</span> than an individual <span class="math inline">\(\alpha_i\)</span>. Therefore, I will calibrate the priors for <span class="math inline">\(\mu_\alpha\)</span> and <span class="math inline">\(\mu_\beta\)</span> so that 99% of the probability mass is in this region, so <span class="math inline">\(s=2.58^{-1}\approx0.39\)</span>. For <span class="math inline">\(g\)</span>, a standard deviation of one seems large to me for both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, because these parameters being greater than one means that the participant will place more weight on the other person’s earnings than their own. Choosing <span class="math inline">\(g=0.079\)</span> means that having <span class="math inline">\(\tau_\alpha&gt;1\)</span> will happen only 5% of the time in the prior. Therefore, all together my priors for this model are:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_\alpha&amp;\sim N(0,0.39^2),\quad \tau_\alpha\sim \mathrm{Cauchy}^+(0,0.79)\\
\mu_\beta&amp;\sim N(0,0.39^2),\quad \tau_\beta\sim \mathrm{Cauchy}^+(0,0.79)\\
\mu_\lambda&amp;\sim N(-5.76,1^2),\quad \tau_\lambda\sim\mathrm{Cauchy}^+(0,0.24)
\end{aligned}
\]</span></p>
</div>
<div id="implementation-and-estimation-in-stan" class="section level4 hasAnchor" number="6.5.1.2">
<h4><span class="header-section-number">6.5.1.2</span> Implementation and estimation in <em>Stan</em><a href="hierarchical-models.html#implementation-and-estimation-in-stan" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This is where all of the work we did in making the representative agent model comes in handy. Here is all we have to do:</p>
<ol style="list-style-type: decimal">
<li>Add in another data variable that keeps track of the participant id (i.e. the <span class="math inline">\(i\)</span> index)</li>
<li>Change the prior data variables so that they are for priors over the population-level parameters</li>
<li>Modify the existing parameters in the parameters block so that they are participant-specific</li>
<li>Add in the new population-level parameters in the parameters block</li>
<li>Specify the hierarchical structure in the model block</li>
</ol>
<p>This might seem like a lot, but it will be exactly the same every time we make a model hierarchical. Importantly, we barely have to modify any of the part of the code that does the individual-level likelihood parts. Here is what I came up with after unashamedly copying and pasting my representative agent model code into a new file:<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb84-1"><a href="hierarchical-models.html#cb84-1" tabindex="-1"></a></span>
<span id="cb84-2"><a href="hierarchical-models.html#cb84-2" tabindex="-1"></a>data <span class="op">{</span></span>
<span id="cb84-3"><a href="hierarchical-models.html#cb84-3" tabindex="-1"></a>  <span class="dt">int</span><span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> n<span class="op">;</span> <span class="co">// number of observations</span></span>
<span id="cb84-4"><a href="hierarchical-models.html#cb84-4" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> self_x<span class="op">;</span> <span class="co">// payoff to self with allocation x</span></span>
<span id="cb84-5"><a href="hierarchical-models.html#cb84-5" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> other_x<span class="op">;</span> <span class="co">// payoff to other with allocation x</span></span>
<span id="cb84-6"><a href="hierarchical-models.html#cb84-6" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> self_y<span class="op">;</span> <span class="co">// payoff to self with allocation y</span></span>
<span id="cb84-7"><a href="hierarchical-models.html#cb84-7" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> other_y<span class="op">;</span> <span class="co">// payoff to other with allocation y</span></span>
<span id="cb84-8"><a href="hierarchical-models.html#cb84-8" tabindex="-1"></a>  <span class="dt">int</span> choice_x<span class="op">[</span>n<span class="op">];</span> <span class="co">// =1 iff allocation x is chosen</span></span>
<span id="cb84-9"><a href="hierarchical-models.html#cb84-9" tabindex="-1"></a>  </span>
<span id="cb84-10"><a href="hierarchical-models.html#cb84-10" tabindex="-1"></a>  <span class="co">/* &lt;----- ADDITION: we need a variable to keep track of the participant ids</span></span>
<span id="cb84-11"><a href="hierarchical-models.html#cb84-11" tabindex="-1"></a><span class="co">  We also need an integer telling us how many participants we have</span></span>
<span id="cb84-12"><a href="hierarchical-models.html#cb84-12" tabindex="-1"></a><span class="co">  */</span></span>
<span id="cb84-13"><a href="hierarchical-models.html#cb84-13" tabindex="-1"></a>  <span class="dt">int</span> id<span class="op">[</span>n<span class="op">];</span></span>
<span id="cb84-14"><a href="hierarchical-models.html#cb84-14" tabindex="-1"></a>  <span class="dt">int</span> nParticipants<span class="op">;</span></span>
<span id="cb84-15"><a href="hierarchical-models.html#cb84-15" tabindex="-1"></a>  </span>
<span id="cb84-16"><a href="hierarchical-models.html#cb84-16" tabindex="-1"></a>  <span class="co">/* &lt;---- DELETION: we now have priors over population-level parameters</span></span>
<span id="cb84-17"><a href="hierarchical-models.html#cb84-17" tabindex="-1"></a><span class="co">  real prior_lambda[2];</span></span>
<span id="cb84-18"><a href="hierarchical-models.html#cb84-18" tabindex="-1"></a><span class="co">  real prior_alpha[2];</span></span>
<span id="cb84-19"><a href="hierarchical-models.html#cb84-19" tabindex="-1"></a><span class="co">  real prior_beta[2];</span></span>
<span id="cb84-20"><a href="hierarchical-models.html#cb84-20" tabindex="-1"></a><span class="co">  */</span></span>
<span id="cb84-21"><a href="hierarchical-models.html#cb84-21" tabindex="-1"></a>  </span>
<span id="cb84-22"><a href="hierarchical-models.html#cb84-22" tabindex="-1"></a>  <span class="co">// &lt;---- ADDITION: data specifying the priors;</span></span>
<span id="cb84-23"><a href="hierarchical-models.html#cb84-23" tabindex="-1"></a>  real prior_mu_alpha<span class="op">[</span><span class="dv">2</span><span class="op">];</span></span>
<span id="cb84-24"><a href="hierarchical-models.html#cb84-24" tabindex="-1"></a>  real prior_mu_beta<span class="op">[</span><span class="dv">2</span><span class="op">];</span></span>
<span id="cb84-25"><a href="hierarchical-models.html#cb84-25" tabindex="-1"></a>  real prior_mu_lambda<span class="op">[</span><span class="dv">2</span><span class="op">];</span></span>
<span id="cb84-26"><a href="hierarchical-models.html#cb84-26" tabindex="-1"></a>  real prior_tau_alpha<span class="op">;</span></span>
<span id="cb84-27"><a href="hierarchical-models.html#cb84-27" tabindex="-1"></a>  real prior_tau_beta<span class="op">;</span></span>
<span id="cb84-28"><a href="hierarchical-models.html#cb84-28" tabindex="-1"></a>  real prior_tau_lambda<span class="op">;</span></span>
<span id="cb84-29"><a href="hierarchical-models.html#cb84-29" tabindex="-1"></a>  </span>
<span id="cb84-30"><a href="hierarchical-models.html#cb84-30" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb84-31"><a href="hierarchical-models.html#cb84-31" tabindex="-1"></a></span>
<span id="cb84-32"><a href="hierarchical-models.html#cb84-32" tabindex="-1"></a>transformed data <span class="op">{</span></span>
<span id="cb84-33"><a href="hierarchical-models.html#cb84-33" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> dX<span class="op">;</span> <span class="co">// disadvantageous inequality at allocation x</span></span>
<span id="cb84-34"><a href="hierarchical-models.html#cb84-34" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> dY<span class="op">;</span> <span class="co">// disadvantageous inequality at allocation y</span></span>
<span id="cb84-35"><a href="hierarchical-models.html#cb84-35" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> aX<span class="op">;</span> <span class="co">// advantageous inequality at allocation X</span></span>
<span id="cb84-36"><a href="hierarchical-models.html#cb84-36" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> aY<span class="op">;</span> <span class="co">// advantageous inequality at allocation X</span></span>
<span id="cb84-37"><a href="hierarchical-models.html#cb84-37" tabindex="-1"></a>  </span>
<span id="cb84-38"><a href="hierarchical-models.html#cb84-38" tabindex="-1"></a>  dX <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>other_x<span class="op">-</span>self_x<span class="op">);</span></span>
<span id="cb84-39"><a href="hierarchical-models.html#cb84-39" tabindex="-1"></a>  dY <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>other_y<span class="op">-</span>self_y<span class="op">);</span></span>
<span id="cb84-40"><a href="hierarchical-models.html#cb84-40" tabindex="-1"></a>  aX <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>self_x<span class="op">-</span>other_x<span class="op">);</span></span>
<span id="cb84-41"><a href="hierarchical-models.html#cb84-41" tabindex="-1"></a>  aY <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>self_y<span class="op">-</span>other_y<span class="op">);</span></span>
<span id="cb84-42"><a href="hierarchical-models.html#cb84-42" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb84-43"><a href="hierarchical-models.html#cb84-43" tabindex="-1"></a>parameters <span class="op">{</span></span>
<span id="cb84-44"><a href="hierarchical-models.html#cb84-44" tabindex="-1"></a>  </span>
<span id="cb84-45"><a href="hierarchical-models.html#cb84-45" tabindex="-1"></a>  <span class="co">/* &lt;--- MODIFICATION: the individual-level parameters are now vectors</span></span>
<span id="cb84-46"><a href="hierarchical-models.html#cb84-46" tabindex="-1"></a><span class="co">  */</span></span>
<span id="cb84-47"><a href="hierarchical-models.html#cb84-47" tabindex="-1"></a>  vector<span class="op">[</span>nParticipants<span class="op">]</span> alpha<span class="op">;</span></span>
<span id="cb84-48"><a href="hierarchical-models.html#cb84-48" tabindex="-1"></a>  vector<span class="op">[</span>nParticipants<span class="op">]</span> beta<span class="op">;</span></span>
<span id="cb84-49"><a href="hierarchical-models.html#cb84-49" tabindex="-1"></a>  vector<span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;[</span>nParticipants<span class="op">]</span> lambda<span class="op">;</span></span>
<span id="cb84-50"><a href="hierarchical-models.html#cb84-50" tabindex="-1"></a>  </span>
<span id="cb84-51"><a href="hierarchical-models.html#cb84-51" tabindex="-1"></a>  <span class="co">// &lt;---- ADDITION: New population-level parameters</span></span>
<span id="cb84-52"><a href="hierarchical-models.html#cb84-52" tabindex="-1"></a>  real mu_alpha<span class="op">;</span></span>
<span id="cb84-53"><a href="hierarchical-models.html#cb84-53" tabindex="-1"></a>  real mu_beta<span class="op">;</span></span>
<span id="cb84-54"><a href="hierarchical-models.html#cb84-54" tabindex="-1"></a>  real mu_lambda<span class="op">;</span></span>
<span id="cb84-55"><a href="hierarchical-models.html#cb84-55" tabindex="-1"></a>  real<span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> tau_alpha<span class="op">;</span></span>
<span id="cb84-56"><a href="hierarchical-models.html#cb84-56" tabindex="-1"></a>  real<span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> tau_beta<span class="op">;</span></span>
<span id="cb84-57"><a href="hierarchical-models.html#cb84-57" tabindex="-1"></a>  real<span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> tau_lambda<span class="op">;</span></span>
<span id="cb84-58"><a href="hierarchical-models.html#cb84-58" tabindex="-1"></a>  </span>
<span id="cb84-59"><a href="hierarchical-models.html#cb84-59" tabindex="-1"></a>  </span>
<span id="cb84-60"><a href="hierarchical-models.html#cb84-60" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb84-61"><a href="hierarchical-models.html#cb84-61" tabindex="-1"></a>model <span class="op">{</span></span>
<span id="cb84-62"><a href="hierarchical-models.html#cb84-62" tabindex="-1"></a>  </span>
<span id="cb84-63"><a href="hierarchical-models.html#cb84-63" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> Ux<span class="op">;</span> <span class="co">// utility of allocation x</span></span>
<span id="cb84-64"><a href="hierarchical-models.html#cb84-64" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> Uy<span class="op">;</span> <span class="co">// utility of allocation y</span></span>
<span id="cb84-65"><a href="hierarchical-models.html#cb84-65" tabindex="-1"></a>  </span>
<span id="cb84-66"><a href="hierarchical-models.html#cb84-66" tabindex="-1"></a>  <span class="co">/* &lt;---- MODIFICATION: Since the individual level parameters are now vectors, </span></span>
<span id="cb84-67"><a href="hierarchical-models.html#cb84-67" tabindex="-1"></a><span class="co">  we need to adjust the utility equations so the right parameters are matched </span></span>
<span id="cb84-68"><a href="hierarchical-models.html#cb84-68" tabindex="-1"></a><span class="co">  with the right observations. This is where the new id variable comes in</span></span>
<span id="cb84-69"><a href="hierarchical-models.html#cb84-69" tabindex="-1"></a><span class="co">  */</span></span>
<span id="cb84-70"><a href="hierarchical-models.html#cb84-70" tabindex="-1"></a>  Ux <span class="op">=</span> self_x<span class="op">-</span>alpha<span class="op">[</span>id<span class="op">]</span> <span class="op">.*</span> dX<span class="op">-</span>beta<span class="op">[</span>id<span class="op">]</span> <span class="op">.*</span> aX<span class="op">;</span></span>
<span id="cb84-71"><a href="hierarchical-models.html#cb84-71" tabindex="-1"></a>  Uy <span class="op">=</span> self_y<span class="op">-</span>alpha<span class="op">[</span>id<span class="op">]</span> <span class="op">.*</span> dY<span class="op">-</span>beta<span class="op">[</span>id<span class="op">]</span> <span class="op">.*</span> aY<span class="op">;</span></span>
<span id="cb84-72"><a href="hierarchical-models.html#cb84-72" tabindex="-1"></a>  </span>
<span id="cb84-73"><a href="hierarchical-models.html#cb84-73" tabindex="-1"></a>  <span class="co">// &lt;---- Slight modification to the likelihood to bring in the id variable</span></span>
<span id="cb84-74"><a href="hierarchical-models.html#cb84-74" tabindex="-1"></a>  choice_x <span class="op">~</span> bernoulli_logit<span class="op">(</span>lambda<span class="op">[</span>id<span class="op">]</span> <span class="op">.*</span> <span class="op">(</span>Ux<span class="op">-</span>Uy<span class="op">));</span></span>
<span id="cb84-75"><a href="hierarchical-models.html#cb84-75" tabindex="-1"></a>  </span>
<span id="cb84-76"><a href="hierarchical-models.html#cb84-76" tabindex="-1"></a>  <span class="co">/* &lt;---- MODIFICATION: priors on individual level parameters are now </span></span>
<span id="cb84-77"><a href="hierarchical-models.html#cb84-77" tabindex="-1"></a><span class="co">  statements about their relationship with population level parameters</span></span>
<span id="cb84-78"><a href="hierarchical-models.html#cb84-78" tabindex="-1"></a><span class="co">  */</span></span>
<span id="cb84-79"><a href="hierarchical-models.html#cb84-79" tabindex="-1"></a>  alpha<span class="op">~</span>normal<span class="op">(</span>mu_alpha<span class="op">,</span>tau_alpha<span class="op">);</span></span>
<span id="cb84-80"><a href="hierarchical-models.html#cb84-80" tabindex="-1"></a>  beta <span class="op">~</span>normal<span class="op">(</span>mu_beta<span class="op">,</span>tau_beta<span class="op">);</span></span>
<span id="cb84-81"><a href="hierarchical-models.html#cb84-81" tabindex="-1"></a>  lambda <span class="op">~</span> lognormal<span class="op">(</span>mu_lambda<span class="op">,</span>tau_lambda<span class="op">);</span></span>
<span id="cb84-82"><a href="hierarchical-models.html#cb84-82" tabindex="-1"></a>  </span>
<span id="cb84-83"><a href="hierarchical-models.html#cb84-83" tabindex="-1"></a>  <span class="co">// &lt;---- ADDITION: priors for population-level parameters</span></span>
<span id="cb84-84"><a href="hierarchical-models.html#cb84-84" tabindex="-1"></a>  mu_alpha <span class="op">~</span> normal<span class="op">(</span>prior_mu_alpha<span class="op">[</span><span class="dv">1</span><span class="op">],</span>prior_mu_alpha<span class="op">[</span><span class="dv">2</span><span class="op">]);</span></span>
<span id="cb84-85"><a href="hierarchical-models.html#cb84-85" tabindex="-1"></a>  mu_beta <span class="op">~</span> normal<span class="op">(</span>prior_mu_beta<span class="op">[</span><span class="dv">1</span><span class="op">],</span>prior_mu_beta<span class="op">[</span><span class="dv">2</span><span class="op">]);</span></span>
<span id="cb84-86"><a href="hierarchical-models.html#cb84-86" tabindex="-1"></a>  mu_lambda <span class="op">~</span> normal<span class="op">(</span>prior_mu_lambda<span class="op">[</span><span class="dv">1</span><span class="op">],</span>prior_mu_lambda<span class="op">[</span><span class="dv">2</span><span class="op">]);</span></span>
<span id="cb84-87"><a href="hierarchical-models.html#cb84-87" tabindex="-1"></a>  </span>
<span id="cb84-88"><a href="hierarchical-models.html#cb84-88" tabindex="-1"></a>  tau_alpha <span class="op">~</span> cauchy<span class="op">(</span><span class="dv">0</span><span class="op">,</span>prior_tau_alpha<span class="op">);</span></span>
<span id="cb84-89"><a href="hierarchical-models.html#cb84-89" tabindex="-1"></a>  tau_beta <span class="op">~</span> cauchy<span class="op">(</span><span class="dv">0</span><span class="op">,</span>prior_tau_beta<span class="op">);</span></span>
<span id="cb84-90"><a href="hierarchical-models.html#cb84-90" tabindex="-1"></a>  tau_lambda <span class="op">~</span> cauchy<span class="op">(</span><span class="dv">0</span><span class="op">,</span>prior_tau_lambda<span class="op">);</span></span>
<span id="cb84-91"><a href="hierarchical-models.html#cb84-91" tabindex="-1"></a>  </span>
<span id="cb84-92"><a href="hierarchical-models.html#cb84-92" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>From here, we can pass the data to <em>Stan</em> and estimate the model:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="hierarchical-models.html#cb85-1" tabindex="-1"></a>file<span class="ot">&lt;-</span><span class="st">&quot;Hierarchical/Hierarchical_BFS2019&quot;</span></span>
<span id="cb85-2"><a href="hierarchical-models.html#cb85-2" tabindex="-1"></a></span>
<span id="cb85-3"><a href="hierarchical-models.html#cb85-3" tabindex="-1"></a><span class="co"># Generate the id variable</span></span>
<span id="cb85-4"><a href="hierarchical-models.html#cb85-4" tabindex="-1"></a>D <span class="ot">&lt;-</span>(</span>
<span id="cb85-5"><a href="hierarchical-models.html#cb85-5" tabindex="-1"></a>  D</span>
<span id="cb85-6"><a href="hierarchical-models.html#cb85-6" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">id =</span> sid <span class="sc">%&gt;%</span> <span class="fu">paste</span>() <span class="sc">%&gt;%</span> <span class="fu">as.factor</span>() <span class="sc">%&gt;%</span> <span class="fu">as.numeric</span>())</span>
<span id="cb85-7"><a href="hierarchical-models.html#cb85-7" tabindex="-1"></a>)</span>
<span id="cb85-8"><a href="hierarchical-models.html#cb85-8" tabindex="-1"></a><span class="co"># only run if I haven&#39;t estimated it yet</span></span>
<span id="cb85-9"><a href="hierarchical-models.html#cb85-9" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_independent.rds&quot;</span>))) {</span>
<span id="cb85-10"><a href="hierarchical-models.html#cb85-10" tabindex="-1"></a> </span>
<span id="cb85-11"><a href="hierarchical-models.html#cb85-11" tabindex="-1"></a>  dStan<span class="ot">&lt;-</span><span class="fu">list</span>(</span>
<span id="cb85-12"><a href="hierarchical-models.html#cb85-12" tabindex="-1"></a>    <span class="at">n=</span><span class="fu">dim</span>(D)[<span class="dv">1</span>],</span>
<span id="cb85-13"><a href="hierarchical-models.html#cb85-13" tabindex="-1"></a>    <span class="at">self_x=</span>D<span class="sc">$</span>self_x,</span>
<span id="cb85-14"><a href="hierarchical-models.html#cb85-14" tabindex="-1"></a>    <span class="at">other_x=</span>D<span class="sc">$</span>other_x,</span>
<span id="cb85-15"><a href="hierarchical-models.html#cb85-15" tabindex="-1"></a>    <span class="at">self_y=</span>D<span class="sc">$</span>self_y,</span>
<span id="cb85-16"><a href="hierarchical-models.html#cb85-16" tabindex="-1"></a>    <span class="at">other_y=</span>D<span class="sc">$</span>other_y,</span>
<span id="cb85-17"><a href="hierarchical-models.html#cb85-17" tabindex="-1"></a>    <span class="at">choice_x=</span>D<span class="sc">$</span>choice_x,</span>
<span id="cb85-18"><a href="hierarchical-models.html#cb85-18" tabindex="-1"></a>    </span>
<span id="cb85-19"><a href="hierarchical-models.html#cb85-19" tabindex="-1"></a>    <span class="at">id =</span> D<span class="sc">$</span>id, </span>
<span id="cb85-20"><a href="hierarchical-models.html#cb85-20" tabindex="-1"></a>    <span class="at">nParticipants =</span> D<span class="sc">$</span>id <span class="sc">|&gt;</span> <span class="fu">unique</span>() <span class="sc">|&gt;</span> <span class="fu">length</span>(),</span>
<span id="cb85-21"><a href="hierarchical-models.html#cb85-21" tabindex="-1"></a>    </span>
<span id="cb85-22"><a href="hierarchical-models.html#cb85-22" tabindex="-1"></a>    <span class="at">prior_mu_alpha   =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.39</span>),</span>
<span id="cb85-23"><a href="hierarchical-models.html#cb85-23" tabindex="-1"></a>    <span class="at">prior_mu_beta    =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.39</span>),</span>
<span id="cb85-24"><a href="hierarchical-models.html#cb85-24" tabindex="-1"></a>    <span class="at">prior_mu_lambda  =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">5.76</span>,<span class="dv">1</span>),</span>
<span id="cb85-25"><a href="hierarchical-models.html#cb85-25" tabindex="-1"></a>    <span class="at">prior_tau_alpha  =</span> <span class="fl">0.79</span>,</span>
<span id="cb85-26"><a href="hierarchical-models.html#cb85-26" tabindex="-1"></a>    <span class="at">prior_tau_beta   =</span> <span class="fl">0.79</span>,</span>
<span id="cb85-27"><a href="hierarchical-models.html#cb85-27" tabindex="-1"></a>    <span class="at">prior_tau_lambda =</span> <span class="fl">0.24</span></span>
<span id="cb85-28"><a href="hierarchical-models.html#cb85-28" tabindex="-1"></a>    </span>
<span id="cb85-29"><a href="hierarchical-models.html#cb85-29" tabindex="-1"></a>  )</span>
<span id="cb85-30"><a href="hierarchical-models.html#cb85-30" tabindex="-1"></a>  Fit<span class="ot">&lt;-</span><span class="fu">stan</span>(<span class="fu">paste0</span>(<span class="st">&quot;Code/&quot;</span>,file,<span class="st">&quot;_independent.stan&quot;</span>),</span>
<span id="cb85-31"><a href="hierarchical-models.html#cb85-31" tabindex="-1"></a>            <span class="at">data=</span>dStan,</span>
<span id="cb85-32"><a href="hierarchical-models.html#cb85-32" tabindex="-1"></a>            <span class="at">seed=</span><span class="dv">42</span>)</span>
<span id="cb85-33"><a href="hierarchical-models.html#cb85-33" tabindex="-1"></a>  <span class="fu">saveRDS</span>(Fit,<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_independent.rds&quot;</span>))</span>
<span id="cb85-34"><a href="hierarchical-models.html#cb85-34" tabindex="-1"></a>}</span>
<span id="cb85-35"><a href="hierarchical-models.html#cb85-35" tabindex="-1"></a></span>
<span id="cb85-36"><a href="hierarchical-models.html#cb85-36" tabindex="-1"></a>Fit<span class="ot">&lt;-</span><span class="fu">readRDS</span>(<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_independent.rds&quot;</span>))</span>
<span id="cb85-37"><a href="hierarchical-models.html#cb85-37" tabindex="-1"></a></span>
<span id="cb85-38"><a href="hierarchical-models.html#cb85-38" tabindex="-1"></a><span class="co"># rstan::summary(Fit)$summary |&gt; View()</span></span></code></pre></div>
<p>Interestingly (to me at least), this one did not take as long as I expected (under ten minutes on my laptop). This is compared to about half an hour for the individual-specific estimations in the previous chapter. Think about this: even though we estimated <span class="math inline">\(3n\)</span> parameters in the individual-specific estimations, and <span class="math inline">\(3n+6\)</span> parameters just now, the second estimation was faster! While I don’t have a well-thought-out explanation for this, my intuition is that the population-level parameters are forming a much more informative “prior” over the individual-level parameters, so sampling the individual-level parameters is less burdensome for <em>Stan</em>.</p>
<p>Anyway, we may as well look at the estimates. As we have so many individual-level parameters, I will just show a summary in Table <a href="hierarchical-models.html#tab:HierarchicalIndependent">6.1</a> for the population-level parameters:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="hierarchical-models.html#cb86-1" tabindex="-1"></a>s<span class="ot">&lt;-</span>rstan<span class="sc">::</span><span class="fu">summary</span>(Fit)<span class="sc">$</span>summary</span>
<span id="cb86-2"><a href="hierarchical-models.html#cb86-2" tabindex="-1"></a></span>
<span id="cb86-3"><a href="hierarchical-models.html#cb86-3" tabindex="-1"></a><span class="co"># identify the rows that contain the population-level parameters.</span></span>
<span id="cb86-4"><a href="hierarchical-models.html#cb86-4" tabindex="-1"></a><span class="co"># These have row names that contain the character &quot;_&quot;</span></span>
<span id="cb86-5"><a href="hierarchical-models.html#cb86-5" tabindex="-1"></a>II<span class="ot">&lt;-</span> <span class="fu">grepl</span>(<span class="st">&quot;_&quot;</span>,<span class="fu">rownames</span>(s))</span>
<span id="cb86-6"><a href="hierarchical-models.html#cb86-6" tabindex="-1"></a>s[II,] <span class="sc">|&gt;</span> <span class="fu">kbl</span>(<span class="at">digits=</span><span class="dv">3</span>,<span class="at">caption=</span><span class="st">&quot;Population estimates of a model assuming a hierarchical independent distribution of individual-level parameters.&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb86-7"><a href="hierarchical-models.html#cb86-7" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<table class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:HierarchicalIndependent">Table 6.1: </span>Population estimates of a model assuming a hierarchical independent distribution of individual-level parameters.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
se_mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
2.5%
</th>
<th style="text-align:right;">
25%
</th>
<th style="text-align:right;">
50%
</th>
<th style="text-align:right;">
75%
</th>
<th style="text-align:right;">
97.5%
</th>
<th style="text-align:right;">
n_eff
</th>
<th style="text-align:right;">
Rhat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mu_alpha
</td>
<td style="text-align:right;">
-0.030
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
-0.058
</td>
<td style="text-align:right;">
-0.040
</td>
<td style="text-align:right;">
-0.030
</td>
<td style="text-align:right;">
-0.020
</td>
<td style="text-align:right;">
-0.001
</td>
<td style="text-align:right;">
3933.694
</td>
<td style="text-align:right;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
mu_beta
</td>
<td style="text-align:right;">
0.233
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
0.195
</td>
<td style="text-align:right;">
0.219
</td>
<td style="text-align:right;">
0.233
</td>
<td style="text-align:right;">
0.246
</td>
<td style="text-align:right;">
0.271
</td>
<td style="text-align:right;">
6327.612
</td>
<td style="text-align:right;">
0.999
</td>
</tr>
<tr>
<td style="text-align:left;">
mu_lambda
</td>
<td style="text-align:right;">
-3.498
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
-3.636
</td>
<td style="text-align:right;">
-3.546
</td>
<td style="text-align:right;">
-3.499
</td>
<td style="text-align:right;">
-3.450
</td>
<td style="text-align:right;">
-3.353
</td>
<td style="text-align:right;">
3126.904
</td>
<td style="text-align:right;">
1.001
</td>
</tr>
<tr>
<td style="text-align:left;">
tau_alpha
</td>
<td style="text-align:right;">
0.165
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
0.138
</td>
<td style="text-align:right;">
0.155
</td>
<td style="text-align:right;">
0.165
</td>
<td style="text-align:right;">
0.175
</td>
<td style="text-align:right;">
0.196
</td>
<td style="text-align:right;">
2065.354
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
tau_beta
</td>
<td style="text-align:right;">
0.248
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
0.219
</td>
<td style="text-align:right;">
0.237
</td>
<td style="text-align:right;">
0.247
</td>
<td style="text-align:right;">
0.259
</td>
<td style="text-align:right;">
0.283
</td>
<td style="text-align:right;">
4071.073
</td>
<td style="text-align:right;">
1.001
</td>
</tr>
<tr>
<td style="text-align:left;">
tau_lambda
</td>
<td style="text-align:right;">
0.829
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.066
</td>
<td style="text-align:right;">
0.708
</td>
<td style="text-align:right;">
0.784
</td>
<td style="text-align:right;">
0.827
</td>
<td style="text-align:right;">
0.871
</td>
<td style="text-align:right;">
0.971
</td>
<td style="text-align:right;">
2094.545
</td>
<td style="text-align:right;">
1.002
</td>
</tr>
<tr>
<td style="text-align:left;">
lp__
</td>
<td style="text-align:right;">
-2345.289
</td>
<td style="text-align:right;">
0.439
</td>
<td style="text-align:right;">
16.981
</td>
<td style="text-align:right;">
-2379.805
</td>
<td style="text-align:right;">
-2356.544
</td>
<td style="text-align:right;">
-2345.241
</td>
<td style="text-align:right;">
-2333.389
</td>
<td style="text-align:right;">
-2312.640
</td>
<td style="text-align:right;">
1493.791
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="correlation-between-individual-level-parameters" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Correlation between individual-level parameters<a href="hierarchical-models.html#correlation-between-individual-level-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now let’s modify the model so that we can estimate a correlation matrix for our participant-level parameters. Conceptually, this is a fairly straightforward step, as we have already assigned priors to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>: by decomposing <span class="math inline">\(\Sigma\)</span> into <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\Omega\)</span>, really the only bit of thinking we need to do is to assign an appropriate prior for <span class="math inline">\(\Omega\)</span>. For this, I choose:</p>
<p><span class="math display">\[
\Omega\sim \mathrm{LKJCorr}(2)
\]</span>
which seems like a reasonably spread-out but still unimodal distribution, as shown in Figure <a href="hierarchical-models.html#fig:HierarchicalLKJ">6.1</a> for <span class="math inline">\(k=3\)</span> participant-level parameters. Here is what I came up with for the code for the hierarchical model with correlated parameters.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb87-1"><a href="hierarchical-models.html#cb87-1" tabindex="-1"></a></span>
<span id="cb87-2"><a href="hierarchical-models.html#cb87-2" tabindex="-1"></a>data <span class="op">{</span></span>
<span id="cb87-3"><a href="hierarchical-models.html#cb87-3" tabindex="-1"></a>  <span class="dt">int</span><span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;</span> n<span class="op">;</span> <span class="co">// number of observations</span></span>
<span id="cb87-4"><a href="hierarchical-models.html#cb87-4" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> self_x<span class="op">;</span> <span class="co">// payoff to self with allocation x</span></span>
<span id="cb87-5"><a href="hierarchical-models.html#cb87-5" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> other_x<span class="op">;</span> <span class="co">// payoff to other with allocation x</span></span>
<span id="cb87-6"><a href="hierarchical-models.html#cb87-6" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> self_y<span class="op">;</span> <span class="co">// payoff to self with allocation y</span></span>
<span id="cb87-7"><a href="hierarchical-models.html#cb87-7" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> other_y<span class="op">;</span> <span class="co">// payoff to other with allocation y</span></span>
<span id="cb87-8"><a href="hierarchical-models.html#cb87-8" tabindex="-1"></a>  <span class="dt">int</span> choice_x<span class="op">[</span>n<span class="op">];</span> <span class="co">// =1 iff allocation x is chosen</span></span>
<span id="cb87-9"><a href="hierarchical-models.html#cb87-9" tabindex="-1"></a>  </span>
<span id="cb87-10"><a href="hierarchical-models.html#cb87-10" tabindex="-1"></a>  <span class="dt">int</span> id<span class="op">[</span>n<span class="op">];</span></span>
<span id="cb87-11"><a href="hierarchical-models.html#cb87-11" tabindex="-1"></a>  <span class="dt">int</span> nParticipants<span class="op">;</span></span>
<span id="cb87-12"><a href="hierarchical-models.html#cb87-12" tabindex="-1"></a>  </span>
<span id="cb87-13"><a href="hierarchical-models.html#cb87-13" tabindex="-1"></a></span>
<span id="cb87-14"><a href="hierarchical-models.html#cb87-14" tabindex="-1"></a>  </span>
<span id="cb87-15"><a href="hierarchical-models.html#cb87-15" tabindex="-1"></a>  vector<span class="op">[</span><span class="dv">2</span><span class="op">]</span> prior_mu<span class="op">[</span><span class="dv">3</span><span class="op">];</span></span>
<span id="cb87-16"><a href="hierarchical-models.html#cb87-16" tabindex="-1"></a>  real prior_tau<span class="op">[</span><span class="dv">3</span><span class="op">];</span></span>
<span id="cb87-17"><a href="hierarchical-models.html#cb87-17" tabindex="-1"></a>  real prior_LKJ<span class="op">;</span></span>
<span id="cb87-18"><a href="hierarchical-models.html#cb87-18" tabindex="-1"></a>  </span>
<span id="cb87-19"><a href="hierarchical-models.html#cb87-19" tabindex="-1"></a>  <span class="co">// number of simulation steps to approximate demand</span></span>
<span id="cb87-20"><a href="hierarchical-models.html#cb87-20" tabindex="-1"></a>  <span class="dt">int</span> nsim<span class="op">;</span> </span>
<span id="cb87-21"><a href="hierarchical-models.html#cb87-21" tabindex="-1"></a>  <span class="co">// Endowment of tokens for demand</span></span>
<span id="cb87-22"><a href="hierarchical-models.html#cb87-22" tabindex="-1"></a>  <span class="dt">int</span> W<span class="op">;</span></span>
<span id="cb87-23"><a href="hierarchical-models.html#cb87-23" tabindex="-1"></a>  <span class="co">// number of prices to evaluate demand at</span></span>
<span id="cb87-24"><a href="hierarchical-models.html#cb87-24" tabindex="-1"></a>  <span class="dt">int</span> nrho<span class="op">;</span></span>
<span id="cb87-25"><a href="hierarchical-models.html#cb87-25" tabindex="-1"></a>  <span class="co">// prices to evaluate demand at</span></span>
<span id="cb87-26"><a href="hierarchical-models.html#cb87-26" tabindex="-1"></a>  vector<span class="op">[</span>nrho<span class="op">]</span> rho<span class="op">;</span> </span>
<span id="cb87-27"><a href="hierarchical-models.html#cb87-27" tabindex="-1"></a>  </span>
<span id="cb87-28"><a href="hierarchical-models.html#cb87-28" tabindex="-1"></a>  </span>
<span id="cb87-29"><a href="hierarchical-models.html#cb87-29" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb87-30"><a href="hierarchical-models.html#cb87-30" tabindex="-1"></a></span>
<span id="cb87-31"><a href="hierarchical-models.html#cb87-31" tabindex="-1"></a>transformed data <span class="op">{</span></span>
<span id="cb87-32"><a href="hierarchical-models.html#cb87-32" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> dX<span class="op">;</span> <span class="co">// disadvantageous inequality at allocation x</span></span>
<span id="cb87-33"><a href="hierarchical-models.html#cb87-33" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> dY<span class="op">;</span> <span class="co">// disadvantageous inequality at allocation y</span></span>
<span id="cb87-34"><a href="hierarchical-models.html#cb87-34" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> aX<span class="op">;</span> <span class="co">// advantageous inequality at allocation X</span></span>
<span id="cb87-35"><a href="hierarchical-models.html#cb87-35" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> aY<span class="op">;</span> <span class="co">// advantageous inequality at allocation X</span></span>
<span id="cb87-36"><a href="hierarchical-models.html#cb87-36" tabindex="-1"></a>  </span>
<span id="cb87-37"><a href="hierarchical-models.html#cb87-37" tabindex="-1"></a>  dX <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>other_x<span class="op">-</span>self_x<span class="op">);</span></span>
<span id="cb87-38"><a href="hierarchical-models.html#cb87-38" tabindex="-1"></a>  dY <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>other_y<span class="op">-</span>self_y<span class="op">);</span></span>
<span id="cb87-39"><a href="hierarchical-models.html#cb87-39" tabindex="-1"></a>  aX <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>self_x<span class="op">-</span>other_x<span class="op">);</span></span>
<span id="cb87-40"><a href="hierarchical-models.html#cb87-40" tabindex="-1"></a>  aY <span class="op">=</span> fmax<span class="op">(</span><span class="dv">0</span><span class="op">,</span>self_y<span class="op">-</span>other_y<span class="op">);</span></span>
<span id="cb87-41"><a href="hierarchical-models.html#cb87-41" tabindex="-1"></a>  </span>
<span id="cb87-42"><a href="hierarchical-models.html#cb87-42" tabindex="-1"></a>  <span class="co">// some things used to produce demand </span></span>
<span id="cb87-43"><a href="hierarchical-models.html#cb87-43" tabindex="-1"></a>  vector<span class="op">[</span>W<span class="op">+</span><span class="dv">1</span><span class="op">]</span> X<span class="op">;</span></span>
<span id="cb87-44"><a href="hierarchical-models.html#cb87-44" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>xx in <span class="dv">1</span><span class="op">:(</span>W<span class="op">+</span><span class="dv">1</span><span class="op">))</span> <span class="op">{</span></span>
<span id="cb87-45"><a href="hierarchical-models.html#cb87-45" tabindex="-1"></a>      X<span class="op">[</span>xx<span class="op">]</span> <span class="op">=</span> xx<span class="op">-</span><span class="dv">1</span><span class="op">;</span></span>
<span id="cb87-46"><a href="hierarchical-models.html#cb87-46" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb87-47"><a href="hierarchical-models.html#cb87-47" tabindex="-1"></a>  </span>
<span id="cb87-48"><a href="hierarchical-models.html#cb87-48" tabindex="-1"></a>  </span>
<span id="cb87-49"><a href="hierarchical-models.html#cb87-49" tabindex="-1"></a>  </span>
<span id="cb87-50"><a href="hierarchical-models.html#cb87-50" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb87-51"><a href="hierarchical-models.html#cb87-51" tabindex="-1"></a>parameters <span class="op">{</span></span>
<span id="cb87-52"><a href="hierarchical-models.html#cb87-52" tabindex="-1"></a>  </span>
<span id="cb87-53"><a href="hierarchical-models.html#cb87-53" tabindex="-1"></a>  vector<span class="op">[</span><span class="dv">3</span><span class="op">]</span> mu<span class="op">;</span> <span class="co">// population mean</span></span>
<span id="cb87-54"><a href="hierarchical-models.html#cb87-54" tabindex="-1"></a>  vector<span class="op">&lt;</span>lower<span class="op">=</span><span class="dv">0</span><span class="op">&gt;[</span><span class="dv">3</span><span class="op">]</span> tau<span class="op">;</span> <span class="co">// population standard deviation</span></span>
<span id="cb87-55"><a href="hierarchical-models.html#cb87-55" tabindex="-1"></a>  cholesky_factor_corr<span class="op">[</span><span class="dv">3</span><span class="op">]</span> L_Omega<span class="op">;</span> <span class="co">// Cholesky factorization of the correlation matrix</span></span>
<span id="cb87-56"><a href="hierarchical-models.html#cb87-56" tabindex="-1"></a>  </span>
<span id="cb87-57"><a href="hierarchical-models.html#cb87-57" tabindex="-1"></a>  matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span>nParticipants<span class="op">]</span> z<span class="op">;</span> <span class="co">// standard normals determinig participants&#39; parameters</span></span>
<span id="cb87-58"><a href="hierarchical-models.html#cb87-58" tabindex="-1"></a>  </span>
<span id="cb87-59"><a href="hierarchical-models.html#cb87-59" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb87-60"><a href="hierarchical-models.html#cb87-60" tabindex="-1"></a>model <span class="op">{</span></span>
<span id="cb87-61"><a href="hierarchical-models.html#cb87-61" tabindex="-1"></a>  </span>
<span id="cb87-62"><a href="hierarchical-models.html#cb87-62" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> Ux<span class="op">;</span> <span class="co">// utility of allocation x</span></span>
<span id="cb87-63"><a href="hierarchical-models.html#cb87-63" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> Uy<span class="op">;</span> <span class="co">// utility of allocation y</span></span>
<span id="cb87-64"><a href="hierarchical-models.html#cb87-64" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> alpha<span class="op">;</span></span>
<span id="cb87-65"><a href="hierarchical-models.html#cb87-65" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> beta<span class="op">;</span></span>
<span id="cb87-66"><a href="hierarchical-models.html#cb87-66" tabindex="-1"></a>  vector<span class="op">[</span>n<span class="op">]</span> lambda<span class="op">;</span></span>
<span id="cb87-67"><a href="hierarchical-models.html#cb87-67" tabindex="-1"></a>  </span>
<span id="cb87-68"><a href="hierarchical-models.html#cb87-68" tabindex="-1"></a>  matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span>nParticipants<span class="op">]</span> theta<span class="op">;</span></span>
<span id="cb87-69"><a href="hierarchical-models.html#cb87-69" tabindex="-1"></a>  </span>
<span id="cb87-70"><a href="hierarchical-models.html#cb87-70" tabindex="-1"></a>  theta <span class="op">=</span> mu<span class="op">*</span>rep_row_vector<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span>nParticipants<span class="op">)</span></span>
<span id="cb87-71"><a href="hierarchical-models.html#cb87-71" tabindex="-1"></a>                    <span class="op">+</span>diag_pre_multiply<span class="op">(</span>tau<span class="op">,</span>L_Omega<span class="op">)*</span>z<span class="op">;</span></span>
<span id="cb87-72"><a href="hierarchical-models.html#cb87-72" tabindex="-1"></a>  </span>
<span id="cb87-73"><a href="hierarchical-models.html#cb87-73" tabindex="-1"></a>  alpha  <span class="op">=</span> theta<span class="op">[</span><span class="dv">1</span><span class="op">,</span>id<span class="op">]</span><span class="ch">&#39;;</span></span>
<span id="cb87-74"><a href="hierarchical-models.html#cb87-74" tabindex="-1"></a>  beta   <span class="op">=</span> theta<span class="op">[</span><span class="dv">2</span><span class="op">,</span>id<span class="op">]</span><span class="ch">&#39;;</span></span>
<span id="cb87-75"><a href="hierarchical-models.html#cb87-75" tabindex="-1"></a>  lambda <span class="op">=</span> exp<span class="op">(</span>theta<span class="op">[</span><span class="dv">3</span><span class="op">,</span>id<span class="op">]</span><span class="ch">&#39;)</span><span class="er">;</span></span>
<span id="cb87-76"><a href="hierarchical-models.html#cb87-76" tabindex="-1"></a></span>
<span id="cb87-77"><a href="hierarchical-models.html#cb87-77" tabindex="-1"></a>  Ux <span class="op">=</span> self_x<span class="op">-</span>alpha <span class="op">.*</span> dX<span class="op">-</span>beta <span class="op">.*</span> aX<span class="op">;</span></span>
<span id="cb87-78"><a href="hierarchical-models.html#cb87-78" tabindex="-1"></a>  Uy <span class="op">=</span> self_y<span class="op">-</span>alpha <span class="op">.*</span> dY<span class="op">-</span>beta <span class="op">.*</span> aY<span class="op">;</span></span>
<span id="cb87-79"><a href="hierarchical-models.html#cb87-79" tabindex="-1"></a>  </span>
<span id="cb87-80"><a href="hierarchical-models.html#cb87-80" tabindex="-1"></a>  choice_x <span class="op">~</span> bernoulli_logit<span class="op">(</span>lambda <span class="op">.*</span> <span class="op">(</span>Ux<span class="op">-</span>Uy<span class="op">));</span></span>
<span id="cb87-81"><a href="hierarchical-models.html#cb87-81" tabindex="-1"></a>  </span>
<span id="cb87-82"><a href="hierarchical-models.html#cb87-82" tabindex="-1"></a>  to_vector<span class="op">(</span>z<span class="op">)</span> <span class="op">~</span> std_normal<span class="op">();</span></span>
<span id="cb87-83"><a href="hierarchical-models.html#cb87-83" tabindex="-1"></a>  </span>
<span id="cb87-84"><a href="hierarchical-models.html#cb87-84" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span>pp in <span class="dv">1</span><span class="op">:</span><span class="dv">3</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb87-85"><a href="hierarchical-models.html#cb87-85" tabindex="-1"></a>    mu<span class="op">[</span>pp<span class="op">]</span> <span class="op">~</span> normal<span class="op">(</span>prior_mu<span class="op">[</span>pp<span class="op">][</span><span class="dv">1</span><span class="op">],</span>prior_mu<span class="op">[</span>pp<span class="op">][</span><span class="dv">2</span><span class="op">]);</span></span>
<span id="cb87-86"><a href="hierarchical-models.html#cb87-86" tabindex="-1"></a>    tau<span class="op">[</span>pp<span class="op">]</span> <span class="op">~</span> cauchy<span class="op">(</span><span class="dv">0</span><span class="er">.0</span><span class="op">,</span>prior_tau<span class="op">[</span>pp<span class="op">]);</span></span>
<span id="cb87-87"><a href="hierarchical-models.html#cb87-87" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb87-88"><a href="hierarchical-models.html#cb87-88" tabindex="-1"></a>  </span>
<span id="cb87-89"><a href="hierarchical-models.html#cb87-89" tabindex="-1"></a>   L_Omega <span class="op">~</span> lkj_corr_cholesky<span class="op">(</span>prior_LKJ<span class="op">);</span></span>
<span id="cb87-90"><a href="hierarchical-models.html#cb87-90" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb87-91"><a href="hierarchical-models.html#cb87-91" tabindex="-1"></a></span>
<span id="cb87-92"><a href="hierarchical-models.html#cb87-92" tabindex="-1"></a>generated quantities <span class="op">{</span></span>
<span id="cb87-93"><a href="hierarchical-models.html#cb87-93" tabindex="-1"></a>  matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span><span class="dv">3</span><span class="op">]</span> Omega<span class="op">;</span></span>
<span id="cb87-94"><a href="hierarchical-models.html#cb87-94" tabindex="-1"></a>  matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span>nParticipants<span class="op">]</span> theta<span class="op">;</span></span>
<span id="cb87-95"><a href="hierarchical-models.html#cb87-95" tabindex="-1"></a>  theta <span class="op">=</span> mu<span class="op">*</span>rep_row_vector<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span>nParticipants<span class="op">)</span></span>
<span id="cb87-96"><a href="hierarchical-models.html#cb87-96" tabindex="-1"></a>                    <span class="op">+</span>diag_pre_multiply<span class="op">(</span>tau<span class="op">,</span>L_Omega<span class="op">)*</span>z<span class="op">;</span></span>
<span id="cb87-97"><a href="hierarchical-models.html#cb87-97" tabindex="-1"></a>  Omega <span class="op">=</span> L_Omega<span class="op">*</span>L_Omega<span class="ch">&#39;;</span></span>
<span id="cb87-98"><a href="hierarchical-models.html#cb87-98" tabindex="-1"></a>  </span>
<span id="cb87-99"><a href="hierarchical-models.html#cb87-99" tabindex="-1"></a>  <span class="co">// store demand in this vector</span></span>
<span id="cb87-100"><a href="hierarchical-models.html#cb87-100" tabindex="-1"></a>  vector<span class="op">[</span>nrho<span class="op">]</span> demand<span class="op">;</span></span>
<span id="cb87-101"><a href="hierarchical-models.html#cb87-101" tabindex="-1"></a>  </span>
<span id="cb87-102"><a href="hierarchical-models.html#cb87-102" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb87-103"><a href="hierarchical-models.html#cb87-103" tabindex="-1"></a>    <span class="co">// simulated standard normals</span></span>
<span id="cb87-104"><a href="hierarchical-models.html#cb87-104" tabindex="-1"></a>    matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span>nsim<span class="op">]</span> zsim<span class="op">;</span></span>
<span id="cb87-105"><a href="hierarchical-models.html#cb87-105" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>rr in <span class="dv">1</span><span class="op">:</span><span class="dv">3</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb87-106"><a href="hierarchical-models.html#cb87-106" tabindex="-1"></a>      zsim<span class="op">[</span>rr<span class="op">,]</span> <span class="op">=</span> to_row_vector<span class="op">(</span>normal_rng<span class="op">(</span>rep_vector<span class="op">(</span><span class="dv">0</span><span class="er">.0</span><span class="op">,</span>nsim<span class="op">),</span>rep_vector<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span>nsim<span class="op">)));</span></span>
<span id="cb87-107"><a href="hierarchical-models.html#cb87-107" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb87-108"><a href="hierarchical-models.html#cb87-108" tabindex="-1"></a>    </span>
<span id="cb87-109"><a href="hierarchical-models.html#cb87-109" tabindex="-1"></a>    <span class="co">// simulate parameters</span></span>
<span id="cb87-110"><a href="hierarchical-models.html#cb87-110" tabindex="-1"></a>    matrix<span class="op">[</span><span class="dv">3</span><span class="op">,</span>nsim<span class="op">]</span> thetasim<span class="op">;</span></span>
<span id="cb87-111"><a href="hierarchical-models.html#cb87-111" tabindex="-1"></a>    thetasim <span class="op">=</span> mu<span class="op">*</span>rep_row_vector<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span>nsim<span class="op">)</span></span>
<span id="cb87-112"><a href="hierarchical-models.html#cb87-112" tabindex="-1"></a>                    <span class="op">+</span>diag_pre_multiply<span class="op">(</span>tau<span class="op">,</span>L_Omega<span class="op">)*</span>zsim<span class="op">;</span></span>
<span id="cb87-113"><a href="hierarchical-models.html#cb87-113" tabindex="-1"></a>                    </span>
<span id="cb87-114"><a href="hierarchical-models.html#cb87-114" tabindex="-1"></a>    vector<span class="op">[</span>nsim<span class="op">]</span> alphasim <span class="op">=</span> thetasim<span class="op">[</span><span class="dv">1</span><span class="op">,]</span><span class="ch">&#39;;</span></span>
<span id="cb87-115"><a href="hierarchical-models.html#cb87-115" tabindex="-1"></a>    vector<span class="op">[</span>nsim<span class="op">]</span> betasim <span class="op">=</span> thetasim<span class="op">[</span><span class="dv">2</span><span class="op">,]</span><span class="ch">&#39;;</span></span>
<span id="cb87-116"><a href="hierarchical-models.html#cb87-116" tabindex="-1"></a>    vector<span class="op">[</span>nsim<span class="op">]</span> lambdasim <span class="op">=</span> exp<span class="op">(</span>thetasim<span class="op">[</span><span class="dv">3</span><span class="op">,]</span><span class="ch">&#39;)</span><span class="er">;</span></span>
<span id="cb87-117"><a href="hierarchical-models.html#cb87-117" tabindex="-1"></a>    </span>
<span id="cb87-118"><a href="hierarchical-models.html#cb87-118" tabindex="-1"></a>    <span class="co">// go through each value of rho </span></span>
<span id="cb87-119"><a href="hierarchical-models.html#cb87-119" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span>rr in <span class="dv">1</span><span class="op">:</span>nrho<span class="op">)</span> <span class="op">{</span></span>
<span id="cb87-120"><a href="hierarchical-models.html#cb87-120" tabindex="-1"></a>      </span>
<span id="cb87-121"><a href="hierarchical-models.html#cb87-121" tabindex="-1"></a>      <span class="co">// dump individual-level expected demand in here</span></span>
<span id="cb87-122"><a href="hierarchical-models.html#cb87-122" tabindex="-1"></a>      vector<span class="op">[</span>nsim<span class="op">]</span> Y<span class="op">;</span></span>
<span id="cb87-123"><a href="hierarchical-models.html#cb87-123" tabindex="-1"></a>      <span class="cf">for</span> <span class="op">(</span>ss in <span class="dv">1</span><span class="op">:</span>nsim<span class="op">)</span> <span class="op">{</span></span>
<span id="cb87-124"><a href="hierarchical-models.html#cb87-124" tabindex="-1"></a>        </span>
<span id="cb87-125"><a href="hierarchical-models.html#cb87-125" tabindex="-1"></a>        <span class="co">// utility of choosing each allocation</span></span>
<span id="cb87-126"><a href="hierarchical-models.html#cb87-126" tabindex="-1"></a>        vector<span class="op">[</span>W<span class="op">+</span><span class="dv">1</span><span class="op">]</span> U <span class="op">=</span> X</span>
<span id="cb87-127"><a href="hierarchical-models.html#cb87-127" tabindex="-1"></a>            <span class="op">-</span>alphasim<span class="op">[</span>ss<span class="op">]*</span>fmax<span class="op">(</span><span class="dv">0</span><span class="er">.0</span><span class="op">,(</span>W<span class="op">-</span>X<span class="op">*(</span><span class="fl">1.0</span><span class="op">+</span>rho<span class="op">[</span>rr<span class="op">]))/</span>rho<span class="op">[</span>rr<span class="op">])</span></span>
<span id="cb87-128"><a href="hierarchical-models.html#cb87-128" tabindex="-1"></a>            <span class="op">-</span>betasim<span class="op">[</span>ss<span class="op">]*</span>fmax<span class="op">(</span><span class="dv">0</span><span class="er">.0</span><span class="op">,(</span>X<span class="op">*(</span><span class="dv">1</span><span class="op">+</span>rho<span class="op">[</span>rr<span class="op">])-</span>W<span class="op">)/</span>rho<span class="op">[</span>rr<span class="op">]);</span></span>
<span id="cb87-129"><a href="hierarchical-models.html#cb87-129" tabindex="-1"></a>        <span class="co">// probability of choosing each allocation</span></span>
<span id="cb87-130"><a href="hierarchical-models.html#cb87-130" tabindex="-1"></a>        vector<span class="op">[</span>W<span class="op">+</span><span class="dv">1</span><span class="op">]</span> pr <span class="op">=</span> softmax<span class="op">(</span>lambdasim<span class="op">[</span>ss<span class="op">]*</span>U<span class="op">);</span></span>
<span id="cb87-131"><a href="hierarchical-models.html#cb87-131" tabindex="-1"></a>        <span class="co">// expected tokens kept</span></span>
<span id="cb87-132"><a href="hierarchical-models.html#cb87-132" tabindex="-1"></a>        real EX <span class="op">=</span> sum<span class="op">(</span>X<span class="op">.*</span>pr<span class="op">);</span></span>
<span id="cb87-133"><a href="hierarchical-models.html#cb87-133" tabindex="-1"></a>        <span class="co">// expected tokens bought for the other participant</span></span>
<span id="cb87-134"><a href="hierarchical-models.html#cb87-134" tabindex="-1"></a>        Y<span class="op">[</span>ss<span class="op">]</span> <span class="op">=</span> <span class="op">(</span>W<span class="op">-</span>EX<span class="op">)/</span>rho<span class="op">[</span>rr<span class="op">];</span></span>
<span id="cb87-135"><a href="hierarchical-models.html#cb87-135" tabindex="-1"></a>        </span>
<span id="cb87-136"><a href="hierarchical-models.html#cb87-136" tabindex="-1"></a>      <span class="op">}</span></span>
<span id="cb87-137"><a href="hierarchical-models.html#cb87-137" tabindex="-1"></a>      </span>
<span id="cb87-138"><a href="hierarchical-models.html#cb87-138" tabindex="-1"></a>      demand<span class="op">[</span>rr<span class="op">]</span> <span class="op">=</span> mean<span class="op">(</span>Y<span class="op">);</span></span>
<span id="cb87-139"><a href="hierarchical-models.html#cb87-139" tabindex="-1"></a>      </span>
<span id="cb87-140"><a href="hierarchical-models.html#cb87-140" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb87-141"><a href="hierarchical-models.html#cb87-141" tabindex="-1"></a>    </span>
<span id="cb87-142"><a href="hierarchical-models.html#cb87-142" tabindex="-1"></a>    </span>
<span id="cb87-143"><a href="hierarchical-models.html#cb87-143" tabindex="-1"></a>    </span>
<span id="cb87-144"><a href="hierarchical-models.html#cb87-144" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb87-145"><a href="hierarchical-models.html#cb87-145" tabindex="-1"></a>  </span>
<span id="cb87-146"><a href="hierarchical-models.html#cb87-146" tabindex="-1"></a>  </span>
<span id="cb87-147"><a href="hierarchical-models.html#cb87-147" tabindex="-1"></a>  </span>
<span id="cb87-148"><a href="hierarchical-models.html#cb87-148" tabindex="-1"></a>  </span>
<span id="cb87-149"><a href="hierarchical-models.html#cb87-149" tabindex="-1"></a>  </span>
<span id="cb87-150"><a href="hierarchical-models.html#cb87-150" tabindex="-1"></a>  </span>
<span id="cb87-151"><a href="hierarchical-models.html#cb87-151" tabindex="-1"></a>  </span>
<span id="cb87-152"><a href="hierarchical-models.html#cb87-152" tabindex="-1"></a>  </span>
<span id="cb87-153"><a href="hierarchical-models.html#cb87-153" tabindex="-1"></a>  </span>
<span id="cb87-154"><a href="hierarchical-models.html#cb87-154" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Here I am implementing both the Cholesky decomposition of <span class="math inline">\(\Omega\)</span> and the vectorization as described in Section 1.13 of the <em>Stan User’s Guide</em>. In particular, note that <span class="math inline">\(\theta\)</span> is <em>not</em> declared in the <code>parameters</code> block. Rather, I use the matrix <code>z</code> of standard normals to generate <span class="math inline">\(\theta\)</span> in the <code>model</code> block:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode c"><code class="sourceCode c"><span id="cb88-1"><a href="hierarchical-models.html#cb88-1" tabindex="-1"></a>theta <span class="op">=</span> mu<span class="op">*</span>rep_row_vector<span class="op">(</span><span class="fl">1.0</span><span class="op">,</span>nParticipants<span class="op">)</span></span>
<span id="cb88-2"><a href="hierarchical-models.html#cb88-2" tabindex="-1"></a>                    <span class="op">+</span>diag_pre_multiply<span class="op">(</span>tau<span class="op">,</span>L_Omega<span class="op">)*</span>z<span class="op">;</span></span></code></pre></div>
<p>Also, since <span class="math inline">\(\Omega\)</span> is not a fundamental parameter, I generate it in the <code>generated quantities</code> block so that we can look at it later.</p>
<p>Here’s how you estimate the model in <em>RStan</em>:<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="hierarchical-models.html#cb89-1" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb89-2"><a href="hierarchical-models.html#cb89-2" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">TRUE</span>)</span>
<span id="cb89-3"><a href="hierarchical-models.html#cb89-3" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb89-4"><a href="hierarchical-models.html#cb89-4" tabindex="-1"></a></span>
<span id="cb89-5"><a href="hierarchical-models.html#cb89-5" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">file.exists</span>(<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_correlated.rds&quot;</span>))) {</span>
<span id="cb89-6"><a href="hierarchical-models.html#cb89-6" tabindex="-1"></a> </span>
<span id="cb89-7"><a href="hierarchical-models.html#cb89-7" tabindex="-1"></a>  dStan<span class="ot">&lt;-</span><span class="fu">list</span>(</span>
<span id="cb89-8"><a href="hierarchical-models.html#cb89-8" tabindex="-1"></a>    <span class="at">n=</span><span class="fu">dim</span>(D)[<span class="dv">1</span>],</span>
<span id="cb89-9"><a href="hierarchical-models.html#cb89-9" tabindex="-1"></a>    <span class="at">self_x=</span>D<span class="sc">$</span>self_x,</span>
<span id="cb89-10"><a href="hierarchical-models.html#cb89-10" tabindex="-1"></a>    <span class="at">other_x=</span>D<span class="sc">$</span>other_x,</span>
<span id="cb89-11"><a href="hierarchical-models.html#cb89-11" tabindex="-1"></a>    <span class="at">self_y=</span>D<span class="sc">$</span>self_y,</span>
<span id="cb89-12"><a href="hierarchical-models.html#cb89-12" tabindex="-1"></a>    <span class="at">other_y=</span>D<span class="sc">$</span>other_y,</span>
<span id="cb89-13"><a href="hierarchical-models.html#cb89-13" tabindex="-1"></a>    <span class="at">choice_x=</span>D<span class="sc">$</span>choice_x,</span>
<span id="cb89-14"><a href="hierarchical-models.html#cb89-14" tabindex="-1"></a>    </span>
<span id="cb89-15"><a href="hierarchical-models.html#cb89-15" tabindex="-1"></a>    <span class="at">id =</span> D<span class="sc">$</span>id, </span>
<span id="cb89-16"><a href="hierarchical-models.html#cb89-16" tabindex="-1"></a>    <span class="at">nParticipants =</span> D<span class="sc">$</span>id <span class="sc">|&gt;</span> <span class="fu">unique</span>() <span class="sc">|&gt;</span> <span class="fu">length</span>(),</span>
<span id="cb89-17"><a href="hierarchical-models.html#cb89-17" tabindex="-1"></a>    </span>
<span id="cb89-18"><a href="hierarchical-models.html#cb89-18" tabindex="-1"></a>    <span class="at">prior_mu =</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.39</span>),</span>
<span id="cb89-19"><a href="hierarchical-models.html#cb89-19" tabindex="-1"></a>                     <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.39</span>),</span>
<span id="cb89-20"><a href="hierarchical-models.html#cb89-20" tabindex="-1"></a>                     <span class="fu">c</span>(<span class="sc">-</span><span class="fl">5.76</span>,<span class="dv">1</span>)</span>
<span id="cb89-21"><a href="hierarchical-models.html#cb89-21" tabindex="-1"></a>                     ),</span>
<span id="cb89-22"><a href="hierarchical-models.html#cb89-22" tabindex="-1"></a>    <span class="at">prior_tau =</span> <span class="fu">c</span>(<span class="fl">0.79</span>,<span class="fl">0.79</span>,<span class="fl">0.24</span>),</span>
<span id="cb89-23"><a href="hierarchical-models.html#cb89-23" tabindex="-1"></a>    <span class="at">prior_LKJ =</span> <span class="dv">2</span>,</span>
<span id="cb89-24"><a href="hierarchical-models.html#cb89-24" tabindex="-1"></a>    </span>
<span id="cb89-25"><a href="hierarchical-models.html#cb89-25" tabindex="-1"></a>    <span class="co"># data needed for demand calculation</span></span>
<span id="cb89-26"><a href="hierarchical-models.html#cb89-26" tabindex="-1"></a>    <span class="co"># (see the &quot;Doing something with the estimates&quot; section)</span></span>
<span id="cb89-27"><a href="hierarchical-models.html#cb89-27" tabindex="-1"></a>    <span class="at">nsim=</span><span class="dv">100</span>,</span>
<span id="cb89-28"><a href="hierarchical-models.html#cb89-28" tabindex="-1"></a>    <span class="at">W =</span> <span class="dv">1000</span>,</span>
<span id="cb89-29"><a href="hierarchical-models.html#cb89-29" tabindex="-1"></a>    <span class="at">nrho =</span> <span class="dv">100</span>,</span>
<span id="cb89-30"><a href="hierarchical-models.html#cb89-30" tabindex="-1"></a>    <span class="at">rho =</span> <span class="fu">seq</span>(<span class="fl">0.1</span>,<span class="dv">10</span>,<span class="at">by=</span><span class="fl">0.1</span>)</span>
<span id="cb89-31"><a href="hierarchical-models.html#cb89-31" tabindex="-1"></a>    </span>
<span id="cb89-32"><a href="hierarchical-models.html#cb89-32" tabindex="-1"></a>    </span>
<span id="cb89-33"><a href="hierarchical-models.html#cb89-33" tabindex="-1"></a>  )</span>
<span id="cb89-34"><a href="hierarchical-models.html#cb89-34" tabindex="-1"></a>  Fit<span class="ot">&lt;-</span><span class="fu">stan</span>(<span class="fu">paste0</span>(<span class="st">&quot;Code/&quot;</span>,file,<span class="st">&quot;_correlated.stan&quot;</span>),</span>
<span id="cb89-35"><a href="hierarchical-models.html#cb89-35" tabindex="-1"></a>            <span class="at">data=</span>dStan,</span>
<span id="cb89-36"><a href="hierarchical-models.html#cb89-36" tabindex="-1"></a>            <span class="at">seed=</span><span class="dv">42</span>)</span>
<span id="cb89-37"><a href="hierarchical-models.html#cb89-37" tabindex="-1"></a>  <span class="fu">saveRDS</span>(Fit,<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_correlated.rds&quot;</span>))</span>
<span id="cb89-38"><a href="hierarchical-models.html#cb89-38" tabindex="-1"></a>}</span>
<span id="cb89-39"><a href="hierarchical-models.html#cb89-39" tabindex="-1"></a></span>
<span id="cb89-40"><a href="hierarchical-models.html#cb89-40" tabindex="-1"></a>Fit<span class="ot">&lt;-</span><span class="fu">readRDS</span>(<span class="fu">paste0</span>(<span class="st">&quot;Outputs/&quot;</span>,file,<span class="st">&quot;_correlated.rds&quot;</span>))</span></code></pre></div>
<p>There are quite a lot of parameters in this model (because we are using data augmentation), so looking at the entire summary is somewhat daunting and not particularly useful. Fortunately, I set up the parameters block so that the first six parameters listed have the same interpretation as the model in the previous section that assumes no correlation between parameters (except that we are estimating <span class="math inline">\(\lambda\)</span> as <span class="math inline">\(\log\lambda\)</span>):</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="hierarchical-models.html#cb90-1" tabindex="-1"></a><span class="fu">summary</span>(Fit)<span class="sc">$</span>summary[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,] <span class="sc">|&gt;</span> <span class="fu">kbl</span>(<span class="at">caption =</span> <span class="st">&quot;Posterior estimates from the model with correlated parameters.&quot;</span>,<span class="at">digits=</span><span class="dv">3</span>) <span class="sc">|&gt;</span> <span class="fu">kable_classic</span>(<span class="at">full_width=</span>F)</span></code></pre></div>
<table class=" lightable-classic" style="color: black; font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:HierarchicalBFS2019correlatedTable">Table 6.2: </span>Posterior estimates from the model with correlated parameters.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
se_mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
2.5%
</th>
<th style="text-align:right;">
25%
</th>
<th style="text-align:right;">
50%
</th>
<th style="text-align:right;">
75%
</th>
<th style="text-align:right;">
97.5%
</th>
<th style="text-align:right;">
n_eff
</th>
<th style="text-align:right;">
Rhat
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
mu[1]
</td>
<td style="text-align:right;">
-0.014
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.015
</td>
<td style="text-align:right;">
-0.044
</td>
<td style="text-align:right;">
-0.024
</td>
<td style="text-align:right;">
-0.014
</td>
<td style="text-align:right;">
-0.004
</td>
<td style="text-align:right;">
0.017
</td>
<td style="text-align:right;">
898.269
</td>
<td style="text-align:right;">
1.008
</td>
</tr>
<tr>
<td style="text-align:left;">
mu[2]
</td>
<td style="text-align:right;">
0.230
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.020
</td>
<td style="text-align:right;">
0.191
</td>
<td style="text-align:right;">
0.216
</td>
<td style="text-align:right;">
0.230
</td>
<td style="text-align:right;">
0.243
</td>
<td style="text-align:right;">
0.269
</td>
<td style="text-align:right;">
1156.227
</td>
<td style="text-align:right;">
1.004
</td>
</tr>
<tr>
<td style="text-align:left;">
mu[3]
</td>
<td style="text-align:right;">
-3.531
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.068
</td>
<td style="text-align:right;">
-3.662
</td>
<td style="text-align:right;">
-3.576
</td>
<td style="text-align:right;">
-3.532
</td>
<td style="text-align:right;">
-3.486
</td>
<td style="text-align:right;">
-3.394
</td>
<td style="text-align:right;">
1593.340
</td>
<td style="text-align:right;">
1.004
</td>
</tr>
<tr>
<td style="text-align:left;">
tau[1]
</td>
<td style="text-align:right;">
0.175
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
0.149
</td>
<td style="text-align:right;">
0.165
</td>
<td style="text-align:right;">
0.174
</td>
<td style="text-align:right;">
0.184
</td>
<td style="text-align:right;">
0.204
</td>
<td style="text-align:right;">
1584.464
</td>
<td style="text-align:right;">
1.001
</td>
</tr>
<tr>
<td style="text-align:left;">
tau[2]
</td>
<td style="text-align:right;">
0.242
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
0.211
</td>
<td style="text-align:right;">
0.231
</td>
<td style="text-align:right;">
0.241
</td>
<td style="text-align:right;">
0.252
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
1692.600
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
<tr>
<td style="text-align:left;">
tau[3]
</td>
<td style="text-align:right;">
0.774
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.062
</td>
<td style="text-align:right;">
0.660
</td>
<td style="text-align:right;">
0.731
</td>
<td style="text-align:right;">
0.771
</td>
<td style="text-align:right;">
0.814
</td>
<td style="text-align:right;">
0.902
</td>
<td style="text-align:right;">
1292.542
</td>
<td style="text-align:right;">
1.001
</td>
</tr>
</tbody>
</table>
<p>To read Table <a href="hierarchical-models.html#tab:HierarchicalBFS2019correlatedTable">6.2</a>, recall that the order of parameters in the vectors <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> is <span class="math inline">\((\alpha_i\ ,\beta_i\ ,\ \log\lambda_i)^\top\)</span>. These population-level parameters are all quite similar to those estimated in the previous section, where we assumed no correlation between the participant-level parameters. However now we also get estimates of the correlations between these parameters, which can be see in tin Table <a href="hierarchical-models.html#tab:HierarchicalBFS2019correlatedTableOMEGA">6.3</a>. In particular, note the strong negative correlation between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>: this is something we would not have beed able to comment on had we just estimated the model without correlation.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="hierarchical-models.html#cb91-1" tabindex="-1"></a>Omega<span class="ot">&lt;-</span><span class="fu">extract</span>(Fit)<span class="sc">$</span>Omega</span>
<span id="cb91-2"><a href="hierarchical-models.html#cb91-2" tabindex="-1"></a></span>
<span id="cb91-3"><a href="hierarchical-models.html#cb91-3" tabindex="-1"></a>OmegaMean<span class="ot">&lt;-</span>Omega <span class="sc">|&gt;</span> <span class="fu">apply</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>),mean)</span>
<span id="cb91-4"><a href="hierarchical-models.html#cb91-4" tabindex="-1"></a>OmegaSD  <span class="ot">&lt;-</span>Omega <span class="sc">|&gt;</span> <span class="fu">apply</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>),sd)</span>
<span id="cb91-5"><a href="hierarchical-models.html#cb91-5" tabindex="-1"></a></span>
<span id="cb91-6"><a href="hierarchical-models.html#cb91-6" tabindex="-1"></a>table<span class="ot">&lt;-</span><span class="fu">paste0</span>(OmegaMean <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">3</span>),</span>
<span id="cb91-7"><a href="hierarchical-models.html#cb91-7" tabindex="-1"></a>              <span class="st">&quot;  (&quot;</span>,OmegaSD <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">3</span>),<span class="st">&quot;)&quot;</span>) <span class="sc">|&gt;</span> <span class="fu">matrix</span>(<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb91-8"><a href="hierarchical-models.html#cb91-8" tabindex="-1"></a></span>
<span id="cb91-9"><a href="hierarchical-models.html#cb91-9" tabindex="-1"></a><span class="fu">colnames</span>(table)<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">alpha$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">beta$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">log</span><span class="sc">\\</span><span class="st">lambda$&quot;</span>)</span>
<span id="cb91-10"><a href="hierarchical-models.html#cb91-10" tabindex="-1"></a><span class="fu">rownames</span>(table)<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">alpha$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">beta$&quot;</span>,<span class="st">&quot;$</span><span class="sc">\\</span><span class="st">log</span><span class="sc">\\</span><span class="st">lambda$&quot;</span>)</span>
<span id="cb91-11"><a href="hierarchical-models.html#cb91-11" tabindex="-1"></a></span>
<span id="cb91-12"><a href="hierarchical-models.html#cb91-12" tabindex="-1"></a>table<span class="sc">|&gt;</span> <span class="fu">kbl</span>(<span class="at">digits=</span><span class="dv">3</span>,<span class="at">caption =</span> <span class="st">&quot;Estimated correlation matrix $</span><span class="sc">\\</span><span class="st">Omega$. Posterior means shown with posterior standard deviations in parentheses.&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb91-13"><a href="hierarchical-models.html#cb91-13" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<table class=" lightable-classic" style="color: black; font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:HierarchicalBFS2019correlatedTableOMEGA">Table 6.3: </span>Estimated correlation matrix <span class="math inline">\(\Omega\)</span>. Posterior means shown with posterior standard deviations in parentheses.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
<span class="math inline">\(\alpha\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(\beta\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(\log\lambda\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\alpha\)</span>
</td>
<td style="text-align:left;">
1 (0)
</td>
<td style="text-align:left;">
-0.689 (0.061)
</td>
<td style="text-align:left;">
-0.594 (0.064)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\beta\)</span>
</td>
<td style="text-align:left;">
-0.689 (0.061)
</td>
<td style="text-align:left;">
1 (0)
</td>
<td style="text-align:left;">
-0.005 (0.088)
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\log\lambda\)</span>
</td>
<td style="text-align:left;">
-0.594 (0.064)
</td>
<td style="text-align:left;">
-0.005 (0.088)
</td>
<td style="text-align:left;">
1 (0)
</td>
</tr>
</tbody>
</table>
<p>Finally, let’s have a look at the model’s shrinkage estimates. Recall that these come from the data-augmentation process, and can be thought of as participant-specific estimates, had we used the parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> that we estimated as our prior for these parameters. As with the previous chapter, I will focus on parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, which are the parameters of the <span class="citation">Fehr and Schmidt (<a href="#ref-FS1999">1999</a>)</span> inequality-aversion model. Also, as with the previous chapter, I will just plot their posterior means to avoid over-plotting. I show these in Figure <a href="hierarchical-models.html#fig:HierarchicalBFS2019correlatedIndPlot">6.3</a></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="hierarchical-models.html#cb92-1" tabindex="-1"></a><span class="co"># extract the right parameters from the Stan Fit object</span></span>
<span id="cb92-2"><a href="hierarchical-models.html#cb92-2" tabindex="-1"></a><span class="co"># and take the mean</span></span>
<span id="cb92-3"><a href="hierarchical-models.html#cb92-3" tabindex="-1"></a>theta<span class="ot">&lt;-</span><span class="fu">extract</span>(Fit)<span class="sc">$</span>theta <span class="sc">|&gt;</span> <span class="fu">apply</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>),mean)<span class="sc">|&gt;</span> <span class="fu">t</span>()</span>
<span id="cb92-4"><a href="hierarchical-models.html#cb92-4" tabindex="-1"></a>dTheta<span class="ot">&lt;-</span><span class="fu">tibble</span>(<span class="at">alpha=</span>theta[,<span class="dv">1</span>],<span class="at">beta=</span>theta[,<span class="dv">2</span>],<span class="at">lambda =</span> <span class="fu">exp</span>(theta[,<span class="dv">3</span>]))</span>
<span id="cb92-5"><a href="hierarchical-models.html#cb92-5" tabindex="-1"></a></span>
<span id="cb92-6"><a href="hierarchical-models.html#cb92-6" tabindex="-1"></a>regions<span class="ot">&lt;-</span><span class="fu">tibble</span>(</span>
<span id="cb92-7"><a href="hierarchical-models.html#cb92-7" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="fu">c</span>(<span class="fl">0.25</span>,<span class="sc">-</span><span class="fl">0.25</span>,<span class="sc">-</span><span class="fl">0.25</span>,<span class="fl">0.25</span>),</span>
<span id="cb92-8"><a href="hierarchical-models.html#cb92-8" tabindex="-1"></a>  <span class="at">beta =</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="sc">-</span><span class="fl">0.5</span>,<span class="fl">0.8</span>,<span class="sc">-</span><span class="fl">0.5</span>),</span>
<span id="cb92-9"><a href="hierarchical-models.html#cb92-9" tabindex="-1"></a>  <span class="at">label =</span> <span class="fu">c</span>(<span class="st">&quot;inequality averse&quot;</span>,</span>
<span id="cb92-10"><a href="hierarchical-models.html#cb92-10" tabindex="-1"></a>            <span class="st">&quot;inequality loving&quot;</span>,</span>
<span id="cb92-11"><a href="hierarchical-models.html#cb92-11" tabindex="-1"></a>            <span class="st">&quot;efficiency loving&quot;</span>,</span>
<span id="cb92-12"><a href="hierarchical-models.html#cb92-12" tabindex="-1"></a>            <span class="st">&quot;competitive&quot;</span></span>
<span id="cb92-13"><a href="hierarchical-models.html#cb92-13" tabindex="-1"></a>            )</span>
<span id="cb92-14"><a href="hierarchical-models.html#cb92-14" tabindex="-1"></a>)</span>
<span id="cb92-15"><a href="hierarchical-models.html#cb92-15" tabindex="-1"></a></span>
<span id="cb92-16"><a href="hierarchical-models.html#cb92-16" tabindex="-1"></a>(  </span>
<span id="cb92-17"><a href="hierarchical-models.html#cb92-17" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb92-18"><a href="hierarchical-models.html#cb92-18" tabindex="-1"></a>    <span class="at">data =</span> dTheta,</span>
<span id="cb92-19"><a href="hierarchical-models.html#cb92-19" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span>alpha,<span class="at">y=</span>beta,<span class="at">color=</span><span class="fu">log</span>(lambda))</span>
<span id="cb92-20"><a href="hierarchical-models.html#cb92-20" tabindex="-1"></a>  )</span>
<span id="cb92-21"><a href="hierarchical-models.html#cb92-21" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_point</span>()</span>
<span id="cb92-22"><a href="hierarchical-models.html#cb92-22" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_text</span>(<span class="at">data=</span>regions,<span class="fu">aes</span>(<span class="at">x=</span>alpha,<span class="at">y=</span>beta,<span class="at">label=</span>label),<span class="at">color=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb92-23"><a href="hierarchical-models.html#cb92-23" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">theme_bw</span>()</span>
<span id="cb92-24"><a href="hierarchical-models.html#cb92-24" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">xlab</span>(<span class="fu">expression</span>(alpha))<span class="sc">+</span><span class="fu">ylab</span>(<span class="fu">expression</span>(beta))</span>
<span id="cb92-25"><a href="hierarchical-models.html#cb92-25" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="dv">0</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb92-26"><a href="hierarchical-models.html#cb92-26" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_vline</span>(<span class="at">xintercept=</span><span class="dv">0</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb92-27"><a href="hierarchical-models.html#cb92-27" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:HierarchicalBFS2019correlatedIndPlot"></span>
<img src="index_files/figure-html/HierarchicalBFS2019correlatedIndPlot-1.png" alt="Posterior mean estimates of individual-level parameters $\alpha$ and $\beta$ from the hierarchical model assuming correlation between the parameters." width="672" />
<p class="caption">
Figure 6.3: Posterior mean estimates of individual-level parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> from the hierarchical model assuming correlation between the parameters.
</p>
</div>
<div id="doing-something-with-the-estimates-1" class="section level4 hasAnchor" number="6.5.2.1">
<h4><span class="header-section-number">6.5.2.1</span> Doing something with the estimates<a href="hierarchical-models.html#doing-something-with-the-estimates-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now that we have a model and estimates that respect the heterogeneity we believe is present in the population, how about we use it to make an out-of-sample prediction? For this exercise, we will use the estimated model to predict a demand curve for charitable giving, <em>a la</em> <span class="citation">Andreoni and Vesterlund (<a href="#ref-AV2001">2001</a>)</span> and <span class="citation">Andreoni and Miller (<a href="#ref-Andreoni2002">2002</a>)</span>. To do this, suppose that a participant has 1000 tokens,<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> which she can either keep, or use to buy income for another participant, who starts out with nothing. Kept tokens generate income of 1 experimental currency unit for the participant, and the participant can buy 1 experimental currency unit for the other participant for a price of <span class="math inline">\(\rho\)</span>. Therefore, if <span class="math inline">\(x\)</span> is the income of the participant, and <span class="math inline">\(y\)</span> is the income of the other, then the budget constraint is:</p>
<p><span class="math display">\[
\begin{aligned}
1000 = x+\rho y
\end{aligned}
\]</span></p>
<p>The participant’s utility function is then:</p>
<p><span class="math display">\[
\begin{aligned}
U_i(x,y)=x-\alpha_i\max\{0,y-x\}-\beta\max\{0,x-y\}
\end{aligned}
\]</span></p>
<p>And substituting the budget constraint into the utility function yields utility just as a function of <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
U_i(x)&amp;=x-\alpha_i\max\left\{0,\frac{1000-x}{\rho}-x\right\}-\beta_i\max\left\{0,x-\frac{1000-x}{\rho}\right\}\\
U_i(x)&amp;=x-\alpha_i\max\left\{0,\frac{1000-x(1+\rho)}{\rho}\right\}-\beta_i\max\left\{0,\frac{x(1+\rho)-1000}{\rho}\right\}
\end{aligned}
\]</span></p>
<p>Now assume that participants use logit choice with the same <span class="math inline">\(\lambda_i\)</span> as in the original experiment.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> So the distribution of choices given <span class="math inline">\((\alpha_i,\beta_i,\lambda_i)\)</span> is:</p>
<p><span class="math display">\[
\Pr(X = x\mid \alpha_i,\beta_i,\lambda_i,\rho)=\frac{\exp(\lambda_i U_i(x))}{\sum_{k=0}^{1000}\exp(\lambda_iU_i(k))}
\]</span></p>
<p>So:</p>
<p><span class="math display">\[
E[X\mid  \alpha_i,\beta_i,\lambda_i,\rho]=\frac{\sum_{x=0}^{1000}x\exp(\lambda_i U_i(x))}{\sum_{k=0}^{1000}\exp(\lambda_iU_i(k))}
\]</span></p>
<p>But what we really want to report is the <em>demand</em> for giving to the other participant, so we need to convert this into income bought for the other participant (<span class="math inline">\(y\)</span>):</p>
<p><span class="math display">\[
E[Y\mid \alpha_i,\beta_i,\lambda_i,\rho] = \frac{1000-E[X\mid  \alpha_i,\beta_i,\lambda_i,\rho]}{\rho}
\]</span></p>
<p>This is participant <span class="math inline">\(i\)</span>’s (average, since they use probabilistic choice) demand for giving. But what we really want is a sense of what the <em>population</em> would demand. Hence, we need to integrate out the individual-specific parameters <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(\beta_i\)</span>, and <span class="math inline">\(\lambda_i\)</span>. Mathematically, we can apply the law of iterated expectations like this, where the left-hand side is what we want to report as a function of <span class="math inline">\(\rho\)</span>:</p>
<p><span class="math display">\[
E[Y\mid \rho]=E\left[E[Y\mid \alpha_i,\beta_i,\lambda_i,\rho]\mid \rho\right]
\]</span></p>
<p>In practice, this is a really hard expectation to take analytically, so instead we will do it with Monte Carlo integration:</p>
<p><span class="math display">\[
\begin{aligned}
E[Y\mid \rho]&amp;\approx \frac1S\sum_{s=1}^SE[Y\mid \alpha_s,\beta_s,\lambda_s,\rho]\\
\begin{pmatrix}
\alpha_s\\ \beta_s \\ \log\lambda_s
\end{pmatrix}&amp;\sim iid N(\mu,\Sigma)
\end{aligned}
\]</span></p>
<p>You can see the implementation of this in the <em>Stan</em> file above. In particular, see the <code>generated quantities</code> block. In general, it is a good idea to use the <code>generated quantities</code> block to compute transformations of the parameters like this, as opposed to doing this outside of <em>Stan</em> in post-estimation. This is for at least two reasons. Firstly, since <em>Stan</em> is fast, this is probably the fastest way for you to compute things. Secondly, <em>Stan</em> gives you all of the convergence diagnostics for these transformed quantities, so you don’t need to worry about (say) having too small an effective sample size or a bad <span class="math inline">\(\hat R\)</span> for these quantities.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p>
<p>Now we can have a look at our estimated demand curve in Figure <a href="hierarchical-models.html#fig:hierarchicaldemand">6.4</a>. For perspective, I also include the demand curve if participants chose allocations that equalized payoffs. This is shown with the red dashed line. Here we can see that participants are generally less generous than this, but get <em>more</em> generous than this for very low prices.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="hierarchical-models.html#cb93-1" tabindex="-1"></a>demand<span class="ot">&lt;-</span><span class="fu">summary</span>(Fit)<span class="sc">$</span>summary <span class="sc">|&gt;</span></span>
<span id="cb93-2"><a href="hierarchical-models.html#cb93-2" tabindex="-1"></a>  <span class="fu">data.frame</span>() <span class="sc">|&gt;</span></span>
<span id="cb93-3"><a href="hierarchical-models.html#cb93-3" tabindex="-1"></a>  <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;parameter&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb93-4"><a href="hierarchical-models.html#cb93-4" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">grepl</span>(<span class="st">&quot;demand&quot;</span>,parameter)) <span class="sc">|&gt;</span></span>
<span id="cb93-5"><a href="hierarchical-models.html#cb93-5" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb93-6"><a href="hierarchical-models.html#cb93-6" tabindex="-1"></a>    <span class="at">price =</span> <span class="fu">seq</span>(<span class="fl">0.1</span>,<span class="dv">10</span>,<span class="at">by=</span><span class="fl">0.1</span>),</span>
<span id="cb93-7"><a href="hierarchical-models.html#cb93-7" tabindex="-1"></a>    <span class="at">equal_split =</span> <span class="dv">1000</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span>price)</span>
<span id="cb93-8"><a href="hierarchical-models.html#cb93-8" tabindex="-1"></a>  )</span>
<span id="cb93-9"><a href="hierarchical-models.html#cb93-9" tabindex="-1"></a></span>
<span id="cb93-10"><a href="hierarchical-models.html#cb93-10" tabindex="-1"></a>(</span>
<span id="cb93-11"><a href="hierarchical-models.html#cb93-11" tabindex="-1"></a>  <span class="fu">ggplot</span>(demand,<span class="fu">aes</span>(<span class="at">x=</span>mean,<span class="at">y=</span>price))</span>
<span id="cb93-12"><a href="hierarchical-models.html#cb93-12" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_line</span>() </span>
<span id="cb93-13"><a href="hierarchical-models.html#cb93-13" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>equal_split,<span class="at">y=</span>price),<span class="at">color=</span><span class="st">&quot;red&quot;</span>,<span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>)</span>
<span id="cb93-14"><a href="hierarchical-models.html#cb93-14" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> X2.<span class="fl">5.</span>,<span class="at">xmax=</span>X97.<span class="fl">5.</span>,<span class="at">y=</span>price),<span class="at">alpha=</span><span class="fl">0.5</span>)</span>
<span id="cb93-15"><a href="hierarchical-models.html#cb93-15" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1500</span>))</span>
<span id="cb93-16"><a href="hierarchical-models.html#cb93-16" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">theme_bw</span>()</span>
<span id="cb93-17"><a href="hierarchical-models.html#cb93-17" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="st">&quot;Price (&quot;</span><span class="sc">*</span>rho<span class="sc">*</span><span class="st">&quot;)&quot;</span>))</span>
<span id="cb93-18"><a href="hierarchical-models.html#cb93-18" tabindex="-1"></a>  <span class="sc">+</span><span class="fu">xlab</span>(<span class="st">&quot;Quantity of experimental currency units demanded for the other participant&quot;</span>)</span>
<span id="cb93-19"><a href="hierarchical-models.html#cb93-19" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:hierarchicaldemand"></span>
<img src="index_files/figure-html/hierarchicaldemand-1.png" alt="Estimted demand curve for giving. Line shows posterior mean estimate, shaded region shows a 95% Bayesian credible region (2.5th-97.5th percentile). Note that since this is a demand curve, the uncertainty is in the *horizontal* coordinates. Dashed red line shows the demand curve if participants equalized payoffs" width="672" />
<p class="caption">
Figure 6.4: Estimted demand curve for giving. Line shows posterior mean estimate, shaded region shows a 95% Bayesian credible region (2.5th-97.5th percentile). Note that since this is a demand curve, the uncertainty is in the <em>horizontal</em> coordinates. Dashed red line shows the demand curve if participants equalized payoffs
</p>
</div>
<p>Note that here we are making an <em>out-of-sample</em> prediction. That is, we are using our parameter estimates to predict how different participants (but drawn from the same population) would behave in a different environment (i.e. the budget set problem, rather than the binary choice task). This is a testable prediction if we run another experiment!</p>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Andreoni2002" class="csl-entry">
Andreoni, James, and John Miller. 2002. <span>“Giving According to GARP: An Experimental Test of the Consistency of Preferences for Altruism.”</span> <em>Econometrica</em> 70 (2): 737–53. <a href="https://www.jstor.org/stable/2692289">https://www.jstor.org/stable/2692289</a>.
</div>
<div id="ref-AV2001" class="csl-entry">
Andreoni, James, and Lise Vesterlund. 2001. <span>“Which Is the Fair Sex? Gender Differences in Altruism.”</span> <em>The Quarterly Journal of Economics</em> 116 (1): 293–312. <a href="https://doi.org/10.1162/003355301556419">https://doi.org/10.1162/003355301556419</a>.
</div>
<div id="ref-Betancourt2015" class="csl-entry">
Betancourt, Michael, and Mark Girolami. 2015. <span>“Hamiltonian Monte Carlo for Hierarchical Models.”</span> <em>Current Trends in Bayesian Methodology with Applications</em> 79 (30): 2–4. <a href="https://doi.org/10.48550/arXiv.1312.0906">https://doi.org/10.48550/arXiv.1312.0906</a>.
</div>
<div id="ref-BFS2019" class="csl-entry">
Bruhin, Adrian, Ernst Fehr, and Daniel Schunk. 2019. <span>“The Many Faces of Human Sociality: Uncovering the Distribution and Stability of Social Preferences.”</span> <em>Journal of the European Economic Association</em> 17 (4): 1025–69.
</div>
<div id="ref-Conte2011" class="csl-entry">
Conte, Anna, John D Hey, and Peter G Moffatt. 2011. <span>“Mixture Models of Choice Under Risk.”</span> <em>Journal of Econometrics</em> 162 (1): 79–88.
</div>
<div id="ref-FS1999" class="csl-entry">
Fehr, Ernst, and Klaus M Schmidt. 1999. <span>“A Theory of Fairness, Competition, and Cooperation.”</span> <em>The Quarterly Journal of Economics</em> 114 (3): 817–68.
</div>
<div id="ref-Moffatt2015" class="csl-entry">
Moffatt, Peter G. 2015. <em>Experimetrics: Econometrics for Experimental Economics</em>. Palgrave Macmillan.
</div>
<div id="ref-StanUsersGuide" class="csl-entry">
Stan Development Team. 2022. <span>“Stan User’s Guide, Version 2.31.”</span>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="22">
<li id="fn22"><p>I.e. <span class="math inline">\(p(A,B)=p(A\mid B)p(B)\)</span><a href="hierarchical-models.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>In fact, sometimes these are also referred to as “priors” in discussion of hierarchical models. I like to stay away from this language, as <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> are parameters that we are trying to estimate, rather than parameters describing our prior beliefs about other parameters.<a href="hierarchical-models.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>This is a really useful section. I have it open in my browser most of the time that I am coding hierarchical models in <em>Stan</em>.<a href="hierarchical-models.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>Here I have deliberately tried to leave as much of this <em>Stan</em> file as unchanged as possible so you can compare it side-by-side with the representative agent model. There are better ways to do this, which I will get to shortly. Most of them take advantage of the stacked vector <span class="math inline">\(\theta\)</span> notation that I have used above.<a href="hierarchical-models.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>This one will take a while. Fold some laundry, write some poetry, find Kakariko Village, or something. (about 17 minutes on my laptop)<a href="hierarchical-models.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>I use 1000 tokens to keep the payoff scales similar to the original experiment.<a href="hierarchical-models.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>This is a somewhat corageous assumption, as in the original experiment participants chose between two things at a time, and now we are asking them to choose between 1,001 things. <a href="hierarchical-models.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>I thank Brian Monroe for this insight.<a href="hierarchical-models.html#fnref29" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="representative-agent-and-participant-specific-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixture-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": false,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
